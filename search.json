[
  {
    "objectID": "hyde-tutorial.html",
    "href": "hyde-tutorial.html",
    "title": "HyDE",
    "section": "",
    "text": "Open in Colab\nWe are going to use LlamaIndex\nWe are going to download this arxiv paper to test HyDE: https://arxiv.org/abs/2305.17066\nimport arxiv\n# Define paper ID (number sequence at the end of the url)\npaper_id = \"2305.17066\"\n\n# Download paper\npaper = next(arxiv.Search(id_list=[\"2305.17066\"]).results()).download_pdf(filename=\"mindstorms-paper.pdf\")\n\npaper\nSo the basic way in which we use LLM’s to perform search over documents is we compare how similar the user’s query is to each chunk of text we have from our documents (i.e., we perform something like cosine similarity between the vector that represents the user’s query and each vector that represents a chunk of text we have).\nThe problem with this approach is that sometimes the user query is not very relatable to the chunk of text the LLM actually needs to provide an answer. So when we perform a similarity search (e.g., cosine similarity) to find the most appropriate chunks of text, we end up retrieving chunks that are not very useful.\nOne way to tackle this issue is to use Hypotetical Document Embeddings"
  },
  {
    "objectID": "hyde-tutorial.html#how-does-hyde-work",
    "href": "hyde-tutorial.html#how-does-hyde-work",
    "title": "HyDE",
    "section": "How does HyDE work?",
    "text": "How does HyDE work?\n\nfrom IPython.display import Image\n\n\nImage(filename=\"HyDE.excalidraw.png\")\n\n\n\n\nSo did HyDE improved our search? TODO: Test accuracy\nHello?\n\nsource\n\ntest_hyde\n\n test_hyde ()\n\nTest the accuracy of HyDE vs a base query"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "llmtools",
    "section": "",
    "text": "This file will become your README and also the index of your documentation."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "llmtools",
    "section": "Install",
    "text": "Install\npip install llmtools"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "llmtools",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2"
  },
  {
    "objectID": "llamaindex.html",
    "href": "llamaindex.html",
    "title": "#",
    "section": "",
    "text": "print(“hello”)\n\nprint('hello')\n\nhello\n\n\n\n!pip install llama-hub\n\nRequirement already satisfied: llama-hub in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (0.0.15)\nRequirement already satisfied: atlassian-python-api in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-hub) (3.39.0)\nRequirement already satisfied: html2text in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-hub) (2020.1.16)\nRequirement already satisfied: llama-index&gt;=0.6.9 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-hub) (0.7.13)\nRequirement already satisfied: psutil in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-hub) (5.9.5)\nRequirement already satisfied: retrying in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-hub) (1.3.4)\nRequirement already satisfied: tiktoken in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-index&gt;=0.6.9-&gt;llama-hub) (0.4.0)\nRequirement already satisfied: dataclasses-json in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-index&gt;=0.6.9-&gt;llama-hub) (0.5.13)\nRequirement already satisfied: langchain&gt;=0.0.218 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-index&gt;=0.6.9-&gt;llama-hub) (0.0.244)\nRequirement already satisfied: sqlalchemy&gt;=2.0.15 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-index&gt;=0.6.9-&gt;llama-hub) (2.0.19)\nRequirement already satisfied: numpy in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-index&gt;=0.6.9-&gt;llama-hub) (1.25.1)\nRequirement already satisfied: tenacity&lt;9.0.0,&gt;=8.2.0 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-index&gt;=0.6.9-&gt;llama-hub) (8.2.2)\nRequirement already satisfied: openai&gt;=0.26.4 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-index&gt;=0.6.9-&gt;llama-hub) (0.27.8)\nRequirement already satisfied: pandas in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-index&gt;=0.6.9-&gt;llama-hub) (2.0.3)\nRequirement already satisfied: urllib3&lt;2 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-index&gt;=0.6.9-&gt;llama-hub) (1.26.16)\nRequirement already satisfied: fsspec&gt;=2023.5.0 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-index&gt;=0.6.9-&gt;llama-hub) (2023.6.0)\nRequirement already satisfied: typing-inspect&gt;=0.8.0 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-index&gt;=0.6.9-&gt;llama-hub) (0.9.0)\nRequirement already satisfied: typing-extensions&gt;=4.5.0 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-index&gt;=0.6.9-&gt;llama-hub) (4.7.1)\nRequirement already satisfied: beautifulsoup4 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-index&gt;=0.6.9-&gt;llama-hub) (4.12.2)\nRequirement already satisfied: nest-asyncio in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from llama-index&gt;=0.6.9-&gt;llama-hub) (1.5.6)\nRequirement already satisfied: deprecated in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from atlassian-python-api-&gt;llama-hub) (1.2.14)\nRequirement already satisfied: requests in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from atlassian-python-api-&gt;llama-hub) (2.31.0)\nRequirement already satisfied: six in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from atlassian-python-api-&gt;llama-hub) (1.16.0)\nRequirement already satisfied: oauthlib in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from atlassian-python-api-&gt;llama-hub) (3.2.2)\nRequirement already satisfied: requests-oauthlib in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from atlassian-python-api-&gt;llama-hub) (1.3.1)\nRequirement already satisfied: PyYAML&gt;=5.4.1 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from langchain&gt;=0.0.218-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (6.0.1)\nRequirement already satisfied: aiohttp&lt;4.0.0,&gt;=3.8.3 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from langchain&gt;=0.0.218-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (3.8.5)\nRequirement already satisfied: langsmith&lt;0.1.0,&gt;=0.0.11 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from langchain&gt;=0.0.218-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (0.0.14)\nRequirement already satisfied: numexpr&lt;3.0.0,&gt;=2.8.4 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from langchain&gt;=0.0.218-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (2.8.4)\nRequirement already satisfied: openapi-schema-pydantic&lt;2.0,&gt;=1.2 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from langchain&gt;=0.0.218-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (1.2.4)\nRequirement already satisfied: pydantic&lt;2,&gt;=1 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from langchain&gt;=0.0.218-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (1.10.12)\nRequirement already satisfied: marshmallow&lt;4.0.0,&gt;=3.18.0 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from dataclasses-json-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (3.20.1)\nRequirement already satisfied: tqdm in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from openai&gt;=0.26.4-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (4.65.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests-&gt;atlassian-python-api-&gt;llama-hub) (3.2.0)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests-&gt;atlassian-python-api-&gt;llama-hub) (3.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests-&gt;atlassian-python-api-&gt;llama-hub) (2023.7.22)\nRequirement already satisfied: greenlet!=0.4.17 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from sqlalchemy&gt;=2.0.15-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (2.0.2)\nRequirement already satisfied: mypy-extensions&gt;=0.3.0 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from typing-inspect&gt;=0.8.0-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (1.0.0)\nRequirement already satisfied: soupsieve&gt;1.2 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from beautifulsoup4-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (2.4.1)\nRequirement already satisfied: wrapt&lt;2,&gt;=1.10 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from deprecated-&gt;atlassian-python-api-&gt;llama-hub) (1.15.0)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from pandas-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (2.8.2)\nRequirement already satisfied: pytz&gt;=2020.1 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from pandas-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (2023.3)\nRequirement already satisfied: tzdata&gt;=2022.1 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from pandas-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (2023.3)\nRequirement already satisfied: regex&gt;=2022.1.18 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from tiktoken-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (2023.6.3)\nRequirement already satisfied: attrs&gt;=17.3.0 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp&lt;4.0.0,&gt;=3.8.3-&gt;langchain&gt;=0.0.218-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (23.1.0)\nRequirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp&lt;4.0.0,&gt;=3.8.3-&gt;langchain&gt;=0.0.218-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (6.0.4)\nRequirement already satisfied: async-timeout&lt;5.0,&gt;=4.0.0a3 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp&lt;4.0.0,&gt;=3.8.3-&gt;langchain&gt;=0.0.218-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (4.0.2)\nRequirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp&lt;4.0.0,&gt;=3.8.3-&gt;langchain&gt;=0.0.218-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (1.9.2)\nRequirement already satisfied: frozenlist&gt;=1.1.1 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp&lt;4.0.0,&gt;=3.8.3-&gt;langchain&gt;=0.0.218-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (1.4.0)\nRequirement already satisfied: aiosignal&gt;=1.1.2 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from aiohttp&lt;4.0.0,&gt;=3.8.3-&gt;langchain&gt;=0.0.218-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (1.3.1)\nRequirement already satisfied: packaging&gt;=17.0 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from marshmallow&lt;4.0.0,&gt;=3.18.0-&gt;dataclasses-json-&gt;llama-index&gt;=0.6.9-&gt;llama-hub) (23.1)\n\n[notice] A new release of pip available: 22.3.1 -&gt; 23.2.1\n[notice] To update, run: pip install --upgrade pip\n\n\n\n!pip install pypdf\n\nRequirement already satisfied: pypdf in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (3.13.0)\n\n[notice] A new release of pip available: 22.3.1 -&gt; 23.2.1\n[notice] To update, run: pip install --upgrade pip\n\n\n\nfrom llama_index import VectorStoreIndex\nfrom llama_hub.file.pdf.base import PDFReader\nfrom pathlib import Path\n\n# Data Loader\nloader = PDFReader()\ndocuments = loader.load_data(file=Path('../codigo_penal_de_la_republica_argentina.pdf'))\n\n\n# Chunking and Embedding of the chunks.\nindex = VectorStoreIndex.from_documents(documents)\n\n\n# Retrieval, node poseprocessing, response synthesis. \nquery_engine = index.as_query_engine()\n\n\n# Run the query engine on a user question.\nresponse = query_engine.query(\"que dice el articulo 14 del codigo penal argentino?\")\n\n\nresponse\n\nResponse(response='\\nEl artículo 14 del Código Penal argentino establece que cuando alguno de los delitos previstos en el Código se haya cometido con la intervención de menores de dieciocho años de edad, la escala penal correspondiente se incrementará en un tercio del mínimo y del máximo respecto de los mayores que hubieren participado en el mismo.', source_nodes=[NodeWithScore(node=TextNode(id_='d153518b-5b34-4273-80a5-0cd16163f917', embedding=None, metadata={'page_label': '11', 'file_name': 'codigo_penal_de_la_republica_argentina.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={&lt;NodeRelationship.SOURCE: '1'&gt;: RelatedNodeInfo(node_id='d3da7c85-c799-460a-be76-8834524070cd', node_type=None, metadata={'page_label': '11', 'file_name': 'codigo_penal_de_la_republica_argentina.pdf'}, hash='ae36a6fa055db3f49b7c47c61c98d3ead0fe13e7bd7d97750d54f061d1e09859')}, hash='c049ec64a8e23fe671db12216bd0a4081de91b302b4b6c407c54eb0481837dfd', text='encuentra privada de su libertad, o la identidad de o tros partícipes o encubridores del hecho, o \\ncualquier otro dato que posibilite su esclarecimiento. \\nEn caso de corresponder prisión o reclusión perpetua, podr á aplicarse prisión o reclusión de \\nOCHO (8) a QUINCE (15) años. \\nSólo podrán gozar de este beneficio quienes tengan una  responsabilidad penal inferior a la de \\nlas personas a quienes identificasen. \\n(Artículo sustituido por art. 12 de la Ley N° 26.364 , B.O. 30/4/2008) \\nARTICULO 41 quater —  Cuando alguno de los delitos previstos en este Código se a cometido \\ncon la intervención de menores de dieciocho años de edad , la escala penal correspondiente se \\nincrementará en un tercio del mínimo y del máximo, re specto de los mayores que hubieren \\nparticipado en el mismo. \\n(Artículo incorporado por art. 1° de la Ley N° 25.767  B.O. 1/9/2003) \\nTITULO VI \\nTENTATIVA \\nARTICULO 42.-  El que con el fin de cometer un delito determinado co mienza su ejecución, \\npero no lo consuma por circunstancias ajenas a su voluntad , sufrirá las penas determinadas en \\nel artículo 44.  \\nARTICULO 43.-  El autor de tentativa no estará sujeto a pena cuando desistiere \\nvoluntariamente del delito.  \\nARTICULO 44.-  La pena que correspondería al agente, si hubiere consum ado el delito, se \\ndisminuirá de un tercio a la mitad.  \\nSi la pena fuere de reclusión perpetua, la pena de la  tentativa será reclusión de quince a \\nveinte años. Si la pena fuese de prisión perpetua, la de tentativa será prisión de diez a quince \\naños.  \\nSi el delito fuera imposible, la pena se disminuirá e n la mitad y podrá reducírsela al mínimo \\nlegal o eximirse de ella, según el grado de peligrosi dad revelada por el delincuente.  \\nTITULO VII \\nPARTICIPACION CRIMINAL \\nARTICULO 45.-  Los que tomasen parte en la ejecución del hecho o presta sen al autor o \\nautores un auxilio o cooperación sin los cuales no habría podido cometerse, tendrán la pena \\nestablecida para el delito. En la misma pena incurrirán  los que hubiesen determinado \\ndirectamente a otro a cometerlo.  \\nARTICULO 46.-  Los que cooperen de cualquier otro modo a la ejecución  del hecho y los que \\npresten una ayuda posterior cumpliendo promesas anterior es al mismo, serán reprimidos con \\nla pena correspondiente al delito, disminuida de un te rcio a la mitad. Si la pena fuere de \\nreclusión perpetua, se aplicará reclusión de quince a vein te años y si fuere de prisión \\nperpetua, se aplicará prisión de diez a quince años.', start_char_idx=0, end_char_idx=2467, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8807650146406303), NodeWithScore(node=TextNode(id_='c141b024-59fa-4629-937a-15fee065d86d', embedding=None, metadata={'page_label': '30', 'file_name': 'codigo_penal_de_la_republica_argentina.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={&lt;NodeRelationship.SOURCE: '1'&gt;: RelatedNodeInfo(node_id='8b732a4a-2bac-4536-92ff-7383b6e0a6da', node_type=None, metadata={'page_label': '30', 'file_name': 'codigo_penal_de_la_republica_argentina.pdf'}, hash='f569556778db476c853123dc79014bf01ab42e3e38fbe5807edccf87d63c227d')}, hash='e5f547ff996193be23f1ce97ab87edf67da0c4de2d59468fba406e5cd863231a', text='equitativo de armonizar el conflicto con mejor resguar do del interés de la víctima. En tal caso \\nla acción penal quedará extinguida; o en el mismo supu esto también podrá disponer la \\naplicación al caso de lo dispuesto por los artículos 76 ter  y 76 quáter del Código Penal.  \\n(Artículo sustituido por art. 15 de la Ley N° 25.087  B.O. 14/5/1999) \\nARTICULO 133.  - Los ascendientes, descendientes, cónyuges, convivientes, a fines en línea \\nrecta, hermanos, tutores, curadores y cualesquiera persona que, con abuso de una relación de \\ndependencia, de autoridad, de poder, de confianza o e ncargo, cooperaren a la perpetración de \\nlos delitos comprendidos en este título serán reprimidos co n la pena de los autores. \\n(Artículo sustituido por art. 13 de la Ley N° 25.087  B.O.14/5/1999) \\n(Nota Infoleg:  rúbricas de los capítulos II, III, IV y V derogadas por art. 1° de la Ley N° \\n25.087  B.O.14/5/1999) \\nTITULO IV \\nDELITOS CONTRA EL ESTADO CIVIL \\nCapítulo I \\nMatrimonios ilegales \\nARTICULO 134.  - Serán reprimidos con prisión de uno a cuatro años, lo s que contrajeren \\nmatrimonio sabiendo ambos que existe impedimento que ca use su nulidad absoluta.  \\nARTICULO 135.  - Serán reprimidos con prisión de dos a seis años:  \\n1º. El que contrajere matrimonio cuando, sabiendo que existe impedimento que cause su \\nnulidad absoluta, ocultare esta circunstancia al otro contr ayente;  \\n2º. El que engañando a una persona, simulare matrimon io con ella.  \\nARTICULO 136.  - El oficial público que a sabiendas autorizare un mat rimonio de los \\ncomprendidos en los artículos anteriores, sufrirá, en su ca so, la pena que en ellos se \\ndetermina.  \\nSi lo autorizare sin saberlo, cuando su ignorancia prove nga de no haber llenado los requisitos \\nque la ley prescribe para la celebración del matrimonio , la pena será de multa de setecientos \\ncincuenta a pesos doce mil quinientos e inhabilitación esp ecial por seis meses a dos años.  \\nSufrirá multa de pesos setecientos cincuenta a pesos doce mi l quinientos el oficial público que, \\nfuera de los demás casos de este artículo, procediere a la celebración de un matrimonio sin \\nhaber observado todas las formalidades exigidas por la l ey.  \\n(Nota Infoleg:  multa actualizada por art. 1° de la Ley N° 24.286  B.O. 29/12/1993) \\nARTICULO 137.  - En la misma pena incurrirá el representante legítim o de un menor impúber \\nque diere el consentimiento para el matrimonio del mi smo.  \\nCapítulo II', start_char_idx=0, end_char_idx=2428, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.878223415137106)], metadata={'d153518b-5b34-4273-80a5-0cd16163f917': {'page_label': '11', 'file_name': 'codigo_penal_de_la_republica_argentina.pdf'}, 'c141b024-59fa-4629-937a-15fee065d86d': {'page_label': '30', 'file_name': 'codigo_penal_de_la_republica_argentina.pdf'}})\n\n\n\n!pip install wandb\n\n\nfrom llama_index import VectorStoreIndex\nfrom llama_index import download_loader\nfrom llama_index import ServiceContext\nfrom llama_index.callbacks import CallbackManager, WandbCallbackHandler\n\n\n# Data Loader\nPDFReader = download_loader(\"PDFReader\")\nloader = PDFReader()\ndocuments = loader.load_data(file=Path('../codigo_penal_de_la_republica_argentina.pdf'))\n\n# initialise WandbCallbackHandler and pass any wandb.init args\nwandb_args = {\"project\":\"ali-test-2\"}\nwandb_callback = WandbCallbackHandler(run_args=wandb_args)\n\n# pass wandb_callback to the service context\ncallback_manager = CallbackManager([wandb_callback])\nservice_context = ServiceContext.from_defaults(callback_manager=callback_manager)\n\n# Chunking and Embedding of the chunks.\nindex = VectorStoreIndex.from_documents(documents, service_context=service_context)\n\n# Retrieval, node poseprocessing, response synthesis.\nquery_engine = index.as_query_engine()\n\n# Run the query engine on a user question.\nresponse = query_engine.query(\"que dice el articulo 14 del codigo penal argentino?\")\n\nresponse\n\nwandb: WARNING Serializing object of type str that is 433504 bytes\nwandb: WARNING Serializing object of type str that is 440774 bytes\nwandb: WARNING Serializing object of type str that is 433504 bytes\nwandb: WARNING Serializing object of type str that is 440774 bytes\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n\n\nResponse(response='\\nEl artículo 14 del Código Penal argentino establece que cuando alguno de los delitos previstos en el Código se haya cometido con la intervención de menores de dieciocho años de edad, la escala penal correspondiente se incrementará en un tercio del mínimo y del máximo respecto de los mayores que hubieren participado en el mismo.', source_nodes=[NodeWithScore(node=TextNode(id_='aab97e14-d6df-4e99-bb5f-43f3cddef01e', embedding=None, metadata={'page_label': '11', 'file_name': 'codigo_penal_de_la_republica_argentina.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={&lt;NodeRelationship.SOURCE: '1'&gt;: RelatedNodeInfo(node_id='5ac916ee-a87f-4bb2-ab54-6f60c12f241d', node_type=None, metadata={'page_label': '11', 'file_name': 'codigo_penal_de_la_republica_argentina.pdf'}, hash='ae36a6fa055db3f49b7c47c61c98d3ead0fe13e7bd7d97750d54f061d1e09859')}, hash='c049ec64a8e23fe671db12216bd0a4081de91b302b4b6c407c54eb0481837dfd', text='encuentra privada de su libertad, o la identidad de o tros partícipes o encubridores del hecho, o \\ncualquier otro dato que posibilite su esclarecimiento. \\nEn caso de corresponder prisión o reclusión perpetua, podr á aplicarse prisión o reclusión de \\nOCHO (8) a QUINCE (15) años. \\nSólo podrán gozar de este beneficio quienes tengan una  responsabilidad penal inferior a la de \\nlas personas a quienes identificasen. \\n(Artículo sustituido por art. 12 de la Ley N° 26.364 , B.O. 30/4/2008) \\nARTICULO 41 quater —  Cuando alguno de los delitos previstos en este Código se a cometido \\ncon la intervención de menores de dieciocho años de edad , la escala penal correspondiente se \\nincrementará en un tercio del mínimo y del máximo, re specto de los mayores que hubieren \\nparticipado en el mismo. \\n(Artículo incorporado por art. 1° de la Ley N° 25.767  B.O. 1/9/2003) \\nTITULO VI \\nTENTATIVA \\nARTICULO 42.-  El que con el fin de cometer un delito determinado co mienza su ejecución, \\npero no lo consuma por circunstancias ajenas a su voluntad , sufrirá las penas determinadas en \\nel artículo 44.  \\nARTICULO 43.-  El autor de tentativa no estará sujeto a pena cuando desistiere \\nvoluntariamente del delito.  \\nARTICULO 44.-  La pena que correspondería al agente, si hubiere consum ado el delito, se \\ndisminuirá de un tercio a la mitad.  \\nSi la pena fuere de reclusión perpetua, la pena de la  tentativa será reclusión de quince a \\nveinte años. Si la pena fuese de prisión perpetua, la de tentativa será prisión de diez a quince \\naños.  \\nSi el delito fuera imposible, la pena se disminuirá e n la mitad y podrá reducírsela al mínimo \\nlegal o eximirse de ella, según el grado de peligrosi dad revelada por el delincuente.  \\nTITULO VII \\nPARTICIPACION CRIMINAL \\nARTICULO 45.-  Los que tomasen parte en la ejecución del hecho o presta sen al autor o \\nautores un auxilio o cooperación sin los cuales no habría podido cometerse, tendrán la pena \\nestablecida para el delito. En la misma pena incurrirán  los que hubiesen determinado \\ndirectamente a otro a cometerlo.  \\nARTICULO 46.-  Los que cooperen de cualquier otro modo a la ejecución  del hecho y los que \\npresten una ayuda posterior cumpliendo promesas anterior es al mismo, serán reprimidos con \\nla pena correspondiente al delito, disminuida de un te rcio a la mitad. Si la pena fuere de \\nreclusión perpetua, se aplicará reclusión de quince a vein te años y si fuere de prisión \\nperpetua, se aplicará prisión de diez a quince años.', start_char_idx=0, end_char_idx=2467, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8807653371758749), NodeWithScore(node=TextNode(id_='d724df88-9b20-4de7-8051-fce1cee5e4ef', embedding=None, metadata={'page_label': '30', 'file_name': 'codigo_penal_de_la_republica_argentina.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={&lt;NodeRelationship.SOURCE: '1'&gt;: RelatedNodeInfo(node_id='21417ad2-1122-43c0-8d67-c8136bf62673', node_type=None, metadata={'page_label': '30', 'file_name': 'codigo_penal_de_la_republica_argentina.pdf'}, hash='f569556778db476c853123dc79014bf01ab42e3e38fbe5807edccf87d63c227d')}, hash='e5f547ff996193be23f1ce97ab87edf67da0c4de2d59468fba406e5cd863231a', text='equitativo de armonizar el conflicto con mejor resguar do del interés de la víctima. En tal caso \\nla acción penal quedará extinguida; o en el mismo supu esto también podrá disponer la \\naplicación al caso de lo dispuesto por los artículos 76 ter  y 76 quáter del Código Penal.  \\n(Artículo sustituido por art. 15 de la Ley N° 25.087  B.O. 14/5/1999) \\nARTICULO 133.  - Los ascendientes, descendientes, cónyuges, convivientes, a fines en línea \\nrecta, hermanos, tutores, curadores y cualesquiera persona que, con abuso de una relación de \\ndependencia, de autoridad, de poder, de confianza o e ncargo, cooperaren a la perpetración de \\nlos delitos comprendidos en este título serán reprimidos co n la pena de los autores. \\n(Artículo sustituido por art. 13 de la Ley N° 25.087  B.O.14/5/1999) \\n(Nota Infoleg:  rúbricas de los capítulos II, III, IV y V derogadas por art. 1° de la Ley N° \\n25.087  B.O.14/5/1999) \\nTITULO IV \\nDELITOS CONTRA EL ESTADO CIVIL \\nCapítulo I \\nMatrimonios ilegales \\nARTICULO 134.  - Serán reprimidos con prisión de uno a cuatro años, lo s que contrajeren \\nmatrimonio sabiendo ambos que existe impedimento que ca use su nulidad absoluta.  \\nARTICULO 135.  - Serán reprimidos con prisión de dos a seis años:  \\n1º. El que contrajere matrimonio cuando, sabiendo que existe impedimento que cause su \\nnulidad absoluta, ocultare esta circunstancia al otro contr ayente;  \\n2º. El que engañando a una persona, simulare matrimon io con ella.  \\nARTICULO 136.  - El oficial público que a sabiendas autorizare un mat rimonio de los \\ncomprendidos en los artículos anteriores, sufrirá, en su ca so, la pena que en ellos se \\ndetermina.  \\nSi lo autorizare sin saberlo, cuando su ignorancia prove nga de no haber llenado los requisitos \\nque la ley prescribe para la celebración del matrimonio , la pena será de multa de setecientos \\ncincuenta a pesos doce mil quinientos e inhabilitación esp ecial por seis meses a dos años.  \\nSufrirá multa de pesos setecientos cincuenta a pesos doce mi l quinientos el oficial público que, \\nfuera de los demás casos de este artículo, procediere a la celebración de un matrimonio sin \\nhaber observado todas las formalidades exigidas por la l ey.  \\n(Nota Infoleg:  multa actualizada por art. 1° de la Ley N° 24.286  B.O. 29/12/1993) \\nARTICULO 137.  - En la misma pena incurrirá el representante legítim o de un menor impúber \\nque diere el consentimiento para el matrimonio del mi smo.  \\nCapítulo II', start_char_idx=0, end_char_idx=2428, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.878223415137106)], metadata={'aab97e14-d6df-4e99-bb5f-43f3cddef01e': {'page_label': '11', 'file_name': 'codigo_penal_de_la_republica_argentina.pdf'}, 'd724df88-9b20-4de7-8051-fce1cee5e4ef': {'page_label': '30', 'file_name': 'codigo_penal_de_la_republica_argentina.pdf'}})\n\n\nSetting up Evaluation using LlamaIndex We have a baseline QA bot, but to even think about improving it, we need a baseline score. This is where evaluating an LLM-based system comes into play. This is a tricky topic and it depends on the system you are trying to build. In this W&B report, “How to Evaluate, Compare, and Optimize LLM Systems?” I have tried to cover the whats and hows of evaluating an LLM-based system. We will not go into detail, but broadly speaking, there are three main categories: Eyeballing: while building a baseline LLM system, we usually eyeball to evaluate the performance of our model. Supervised: This is the recommended way of evaluation where you involve humans to generate an annotated eval dataset for evaluation. LLMs evaluate LLMs: In this paradigm, we leverage a powerful LLM to generate proxy targets based on some context. In our case of a QA bot, we can ask an LLM to generate question-answer pairs.\nGenerating Questions using LlamaIndex Using LlamaIndex’s, DatasetGenerator, we can easily generate questions that can be used to evaluate using one of the following strategies but not limited to: Evaluating response for hallucination: Is the generated response coming from the provided context, or is it making up things? Relevance of the retrieved chunks: Evaluate each retrieved chunk (node) against the generated response to see if that node contains the answer to the query. Evaluating the answer quality: Does the query + generated response come from the provided context?\nUsing DatasetGenerator is easy, and one can pass the loaded documents to the DatasetGenerator.from_documents method. Calling generate_questions_from_nodes() on the object’s instance will generate N questions per chunk. The default chunk size is 512, and N is 10. You might quickly realize that it will take a long time and a lot of API calls to generate a lot of questions. Let’s customize the data generation process.\n\nresponse\n\nResponse(response='\\nKrzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean.', source_nodes=[NodeWithScore(node=TextNode(id_='6483ae64-5538-48e6-ba8f-02452e417a6d', embedding=None, metadata={'page_label': '10', 'file_name': 'mindstorms.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={&lt;NodeRelationship.SOURCE: '1'&gt;: RelatedNodeInfo(node_id='18208c46-0337-4f62-b2b6-17276f0c5dbd', node_type=None, metadata={'page_label': '10', 'file_name': 'mindstorms.pdf'}, hash='169ecb16f411f01b9da078f9ea1646834d47b15ed9f401393b3ef0005caa3b78'), &lt;NodeRelationship.PREVIOUS: '2'&gt;: RelatedNodeInfo(node_id='084f371f-867b-43d3-a417-bd9567408cad', node_type=None, metadata={'page_label': '10', 'file_name': 'mindstorms.pdf'}, hash='40b65e30ddd22681bf1df3f671585575dac2643bdbf1c4f48b2efa21f3e83246')}, hash='1015ca2b568d94b6ae938cde2f5dede7e38cbb587e2719d1f41f13ae6e754920', text='Chenliang Li, Haiyang Xu, Junfeng Tian, Wei Wang, Ming Yan,\\nBin Bi, Jiabo Ye, Hehong Chen, Guohai Xu, Zheng Cao, et al.', start_char_idx=8338, end_char_idx=8457, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7829675888761374), NodeWithScore(node=TextNode(id_='f49d1880-b517-4167-82d0-c57480ba915d', embedding=None, metadata={'page_label': '13', 'file_name': 'mindstorms.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={&lt;NodeRelationship.SOURCE: '1'&gt;: RelatedNodeInfo(node_id='23d3bdc6-398b-466f-b211-72cf13f8ecaa', node_type=None, metadata={'page_label': '13', 'file_name': 'mindstorms.pdf'}, hash='18ab5cdbf4abda2e53a7489bae21155a8c0d368b98733965bc18020b95a08b71'), &lt;NodeRelationship.PREVIOUS: '2'&gt;: RelatedNodeInfo(node_id='f3efa13c-48bf-4bff-abe8-97cce45e8422', node_type=None, metadata={'page_label': '13', 'file_name': 'mindstorms.pdf'}, hash='dec0edde35c9c4eea12f67c7c11260ef5ba701d073dfbfe3e333fc5db9a5548f')}, hash='d81351f14e0a07ccbe38bbf3cb00fb78548bc8862b8fd8f222ad9e6d71a63dcc', text='Krzysztof Maziarz, Andy\\nDavis, Quoc Le, Geoffrey Hinton, and Jeff Dean. Outrageously\\nlarge neural networks: The sparsely-gated mixture-of-experts\\nlayer.arXiv preprint arXiv:1701.06538, 2017.', start_char_idx=8235, end_char_idx=8425, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7795502192052534)], metadata={'6483ae64-5538-48e6-ba8f-02452e417a6d': {'page_label': '10', 'file_name': 'mindstorms.pdf'}, 'f49d1880-b517-4167-82d0-c57480ba915d': {'page_label': '13', 'file_name': 'mindstorms.pdf'}})\n\n\n\nfrom llama_index.evaluation import DatasetGenerator, QueryResponseEvaluator\nfrom llama_index import (\n    SimpleDirectoryReader,\n    VectorStoreIndex,\n    ServiceContext,\n    LLMPredictor,\n    Response,\n)\nfrom llama_index.llms import OpenAI\n\nimport logging\nimport sys\nimport pandas as pd\n\n\n# Let's use GPT 3.5 as our LLM of choice.\nllm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\nservice_context = ServiceContext.from_defaults(llm=llm, callback_manager=callback_manager)\n\n\n# Let's just use a meaningful subset of the shuffled documents.\nrandom_documents = copy.deepcopy(documents)\nrandom.shuffle(random_documents)\nrandom_documents = random_documents[:10]\n\n\n# Let's reduce the number of questions per chunk.\ndata_generator = DatasetGenerator.from_documents(\n    random_documents, service_context=service_context, num_questions_per_chunk=2\n)\n\n\n# Generate questions\neval_questions = data_generator.generate_questions_from_nodes()\neval_questions\n\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n\n\n['What are the potential penalties for individuals who obstruct the extinguishing of a fire or the defense against a disaster, according to the Argentine Penal Code?',\n 'How does the Argentine Penal Code differentiate the penalties for causing a fire or other damages due to negligence versus those that result in endangering or causing the death of a person?',\n 'What is the potential penalty for carrying unauthorized weapons according to the Penal Code of Argentina?',\n 'Under what circumstances can the penalty for carrying weapons be reduced according to the Penal Code of Argentina?',\n 'How does Article 172 of the Argentine Penal Code define the crime of fraud? Provide examples of the different fraudulent acts mentioned in the article.',\n 'According to Article 173 of the Argentine Penal Code, what are some specific cases of fraud and the corresponding penalties? Explain each case briefly.',\n 'What actions can be considered as defrauding the rights of cocontractors according to the Argentine Penal Code?',\n 'Under what circumstances can the execution of a property be considered illegal according to the Argentine Penal Code?',\n 'What are the penalties for the crime of abigeato according to the Argentine Penal Code?',\n 'Under what circumstances would a person receive a special disqualification in addition to their sentence for a crime under the Abigeato chapter of the Penal Code?',\n 'What are the potential penalties for a public official who requires the assistance of the police against the execution of legal provisions or judicial orders?',\n 'What are the consequences for a military personnel who abandons their service or deserts during a time of armed conflict or catastrophe?',\n 'What is the penalty for a military personnel who, due to negligence or failure to follow regulations, causes the death of one or more people during a conflict or disaster situation?',\n 'When does the law mentioned in the context information come into effect and what measures will be taken during the six-month period before its implementation?',\n 'What are the potential penalties for individuals who knowingly enter into an illegal marriage, despite being aware of an impediment that would render the marriage null and void?',\n 'Who can be held criminally liable for assisting in the commission of crimes outlined in this section of the penal code, and what penalties may they face?',\n 'What are the penalties for falsifying official seals, stamps, and marks according to the Argentine Penal Code?',\n 'What actions can result in imprisonment according to Article 287 of the Argentine Penal Code?',\n 'What is the penalty for knowingly using or selling invalidated stamps, seals, or marks, as mentioned in the given context information?',\n 'According to the context information, what is the range of fines for the offense of using or selling invalidated stamps, seals, or marks?',\n 'According to the Penal Code of Argentina, under what circumstances is abortion not considered a punishable offense?',\n \"What are the potential penalties for causing harm to another person's body or health, as outlined in the Penal Code of Argentina?\",\n \"What are the possible circumstances under which a person can be held liable for causing harm to another person's body or health according to the Argentine Penal Code?\",\n 'How does the minimum penalty for causing injuries described in articles 90 or 91 change if certain circumstances specified in the second paragraph of article 84 are present?',\n 'According to Article 52 of the Argentine Penal Code, under what circumstances can a person be sentenced to indefinite reclusion as an accessory to their last conviction?',\n 'What are the conditions that must be met for a convicted individual to be eligible for conditional release after serving a period of indefinite reclusion as stated in Article 53 of the Argentine Penal Code?',\n 'According to Article 54 of the Argentine Penal Code, what happens when a criminal act falls under multiple penalties?',\n 'How does Article 55 of the Argentine Penal Code determine the minimum penalty for a defendant when multiple independent acts are punished with the same type of penalty?',\n \"According to Article 175 bis of the Argentine Penal Code, what is the punishment for someone who takes advantage of another person's need, inexperience, or vulnerability to obtain excessive interest rates or extortive guarantees?\",\n 'In the case of a fraudulent bankruptcy, what are some of the actions that can lead to imprisonment and special disqualification for a period of time, as stated in Articles 176 and 177 of the Argentine Penal Code?',\n 'According to the context information, who are the individuals that could be held responsible for the bankruptcy of a bank or financial institution?',\n 'In the given context, what positions or roles within a failed company or establishment could potentially face legal consequences?',\n 'According to Article 119 of the Argentine Penal Code, what are the potential penalties for sexually abusing a minor under the age of thirteen?',\n 'In Article 120 of the Argentine Penal Code, what are the circumstances that can result in a higher penalty for someone who engages in sexual acts with a person under the age of sixteen?',\n 'What is the significance of the Law N° 25.087 in relation to the articles 121, 122, and 123 of the Argentine Penal Code?',\n 'Why were the articles 121, 122, and 123 of the Argentine Penal Code derogated by the Law N° 25.087?']\n\n\nEvaluating for Hallucination The LLM generates a response using the provided context (chunks). In this evaluation strategy, we ask another LLM (GPT-4) to say a YES if the response was generated using the provided context and NO otherwise. One can implement this strategy in LlamaIndex using the ResponseEvaluator class. In this evaluation mode, we call the evaluate method of the instance of this class.\n\nfrom llama_index.evaluation import ResponseEvaluator\n\n\n\ngpt3 = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\nservice_context_gpt3 = ServiceContext.from_defaults(llm=gpt3)\nevaluator_gpt3 = QueryResponseEvaluator(service_context=service_context_gpt3)\n# create vector index\nvector_index = VectorStoreIndex.from_documents(\n    documents, service_context=service_context_gpt3\n)\n\n\n# define jupyter display function\ndef display_eval_df(query: str, response: Response, eval_result: str) -&gt; None:\n    eval_df = pd.DataFrame(\n        {\n            \"Query\": query,\n            \"Response\": str(response),\n            \"Source\": response.source_nodes[0].node.get_content()[:1000] + \"...\",\n            \"Evaluation Result\": eval_result,\n        },\n        index=[0],\n    )\n    eval_df = eval_df.style.set_properties(\n        **{\n            \"inline-size\": \"600px\",\n            \"overflow-wrap\": \"break-word\",\n        },\n        subset=[\"Response\", \"Source\"]\n    )\n    display(eval_df)\n\n\nquery_engine = vector_index.as_query_engine()\nresponse_vector = query_engine.query(eval_questions[1])\neval_result = evaluator_gpt3.evaluate(eval_questions[1], response_vector)\n\n\ndisplay_eval_df(eval_questions[1], response_vector, eval_result)\n\n\n\n\n\n\n \nQuery\nResponse\nSource\nEvaluation Result\n\n\n\n\n0\nHow does the Argentine Penal Code differentiate the penalties for causing a fire or other damages due to negligence versus those that result in endangering or causing the death of a person?\nAccording to the context information provided, the Argentine Penal Code differentiates the penalties for causing a fire or other damages due to negligence from those that result in endangering or causing the death of a person based on the severity of the consequences. For causing a fire, explosion, or flood with common danger to property, the penalty is imprisonment or confinement for three to ten years. If the fire or destruction is caused by other means, such as the destruction of crops, forests, livestock, or other plantations, the penalty is also imprisonment or confinement for three to ten years. However, if there is danger to a public archive, library, museum, military arsenal, or if there is danger of death to a person, the penalties increase. The penalty for endangering a public archive, for example, is imprisonment or confinement for three to fifteen years. If the act results in the immediate death of a person, the penalty is imprisonment or confinement for eight to twenty years. Therefore, the Argentine Penal Code differentiates the penalties based on the level of danger or harm caused, with more severe penalties for acts that result in endangering or causing the death of a person.\nel que por imprudencia o negligencia, por impericia en su arte o profesión, o por inobservanci a de los reglamentos o deberes a su cargo, causare a otro un daño en el cuerpo o en la salud . Si las lesiones fueran de las descritas en los artículos 90 ó 91 y concurriera alguna de las circunstancias previstas en el segundo párrafo del artículo 84, el mínimo de la pena prevista en el primer párrafo, será de seis meses o multa de tres mil pesos e inhabilitación especial por dieciocho meses. (Artículo sustituido por art. 2° de la Ley N° 25.189 28/10/1999)...\nYES\n\n\n\n\n\n\n!pip install nltk\n\nCollecting nltk\n  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 6.8 MB/s eta 0:00:00m eta 0:00:010:01:01\nRequirement already satisfied: click in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from nltk) (8.1.6)\nCollecting joblib\n  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 302.0/302.0 kB 6.2 MB/s eta 0:00:00 MB/s eta 0:00:01\nRequirement already satisfied: regex&gt;=2021.8.3 in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from nltk) (2023.6.3)\nRequirement already satisfied: tqdm in /home/franfram/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from nltk) (4.65.0)\nInstalling collected packages: joblib, nltk\nSuccessfully installed joblib-1.3.1 nltk-3.8.1\n\n[notice] A new release of pip available: 22.3.1 -&gt; 23.2.1\n[notice] To update, run: pip install --upgrade pip\n\n\n\nfrom llama_index import *\n\n\nkeyword_index = KeywordTableIndex.from_documents(documents)\n\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/franfram/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n\n\n\nkeyword_index\n\n&lt;llama_index.indices.keyword_table.base.KeywordTableIndex at 0x7f52b8d7cad0&gt;"
  },
  {
    "objectID": "02_Train_vectorstore_index_with_Llamaindex.html",
    "href": "02_Train_vectorstore_index_with_Llamaindex.html",
    "title": "llmtools",
    "section": "",
    "text": "Open in Colab\n\n\n\n# @title Install and import dependencies\n# !pip install llama-index transformers accelerate sentence_transformers\n\n#| code-fold\n\nfrom llama_index import ServiceContext, VectorStoreIndex, SimpleDirectoryReader, set_global_service_context\nimport transformers\nfrom llama_index.llms import HuggingFaceLLM\nimport torch\nimport os\n\n/home/franfram/llmtools/llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\nSet dummy OpenAI API key\n\n# @title Set dummy OpenAI API key\n# @markdown Without it, we will run into an authentication error ('no API key set')\n\n\n#| code-fold\nos.environ['OPENAI_API_KEY']='sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n\n\n# @title Set embedding model\n# @markdown Highest rated in [MTEB benchmark](https://huggingface.co/spaces/mteb/leaderboard) for document retrieval is thenlper/gte-large\n\n\n#| code-fold\nmodel = 'thenlper/gte-large' # @param {type:'string'}\nif not os.path.exists('gte-large'): \n  !git clone https://huggingface.co/thenlper/gte-large\n  print(\"Cloning repo\")\nelse:\n  print(\"repo already exists\")\n\n#remove git repo to avoid issues\n!rm -rf ./gte-large/.git\n\n\nservice_context = ServiceContext.from_defaults(\n  embed_model=\"local:\" + model\n)\nset_global_service_context(service_context)\n\nrepo already exists\n\n\nNo sentence-transformers model found with name /home/franfram/.cache/torch/sentence_transformers/thenlper_gte-large. Creating a new one with MEAN pooling.\n\n\n\n# @title Initialize empty index with the given context to use our local embedding model\n\n\n#| code-fold\nindex = VectorStoreIndex([], service_context=service_context)\n\n\n# @title Define recursive function to add documents to the index by travelling folders and subfolders\n\n#| code-fold\n#| export\ndef recursive_folder_search(folder):\n    # get a list of all subdirectories in the given folder\n    subdirectories = [f.path for f in os.scandir(folder) if f.is_dir()]\n    # if there are no subdirectories, run the code\n    if len(subdirectories) == 0:\n        f=0\n        for files in os.listdir(folder):\n          document = SimpleDirectoryReader(folder).load_data()[f]\n          f+=1\n          index.insert(document)\n    else:\n        # if there are subdirectories, recursively call this function on each subdirectory\n        for subdirectory in subdirectories:\n            recursive_folder_search(subdirectory)\n\nhello\n\n# @title Train vectorstore index\nrecursive_folder_search(\"../dataset\")\n\n\n# @title Save index to disk\nindex.storage_context.persist(persist_dir=\"indexes/\")\n\n\n# @title Retrieve chunks\n# @markdown Once finished, we can use the already loaded index to test and retrieve chunks\nretriever = index.as_retriever()\nsearchTerm = 'search term' # @param {type:'string'}\nnodes = retriever.retrieve(searchTerm)\n\nprint(nodes)"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "hello_llm\n\n hello_llm ()\n\nThe LLM talks to you\n\nfrom llama_index import *\n\n\n\n\ningests_documents\n\n ingests_documents ()\n\ningests documents\n\n\n\nquery_llm\n\n query_llm ()\n\nQueries the LLM"
  },
  {
    "objectID": "advance_query_engine_with_llamaindex.html",
    "href": "advance_query_engine_with_llamaindex.html",
    "title": "Use Keyword based Index",
    "section": "",
    "text": "/Users/ayushthakur/integrations/llamaindex/llama_index\nimport os\nfrom pathlib import Path\n\nimport llama_index\nprint(llama_index.__version__)\nfrom llama_index import VectorStoreIndex\nfrom llama_index import download_loader\n\n0.7.10.post1\nfrom dotenv import load_dotenv\nload_dotenv(\"/Users/ayushthakur/integrations/llamaindex/apis.env\")\n\nimport openai\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\nos.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
  },
  {
    "objectID": "advance_query_engine_with_llamaindex.html#simple-query-engine",
    "href": "advance_query_engine_with_llamaindex.html#simple-query-engine",
    "title": "Use Keyword based Index",
    "section": "Simple Query Engine",
    "text": "Simple Query Engine\nTo set benchmark.\n\nPDFReader = download_loader(\"PDFReader\")\n\nloader = PDFReader()\ndocuments = loader.load_data(file=Path('../llama2.pdf'))\n\n\nfrom llama_index import ServiceContext\nfrom llama_index.callbacks import CallbackManager, WandbCallbackHandler\n\n# initialise WandbCallbackHandler and pass any wandb.init args\nwandb_args = {\"project\":\"llama-index-report\"}\nwandb_callback = WandbCallbackHandler(run_args=wandb_args)\n\n# pass wandb_callback to the service context\ncallback_manager = CallbackManager([wandb_callback])\nservice_context = ServiceContext.from_defaults(callback_manager=callback_manager)\n\nwandb: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/v7h22l9i\nwandb: `WandbCallbackHandler` is currently in beta.\nwandb: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n\n\n\nindex = VectorStoreIndex.from_documents(documents, service_context=service_context)\n\n\nquery_engine = index.as_query_engine()\n\n\nresponse = query_engine.query(\"Who wrote this paper?\")\nprint(response, sep=\"\\n\")\n\n\nThis paper was written by a large group of contributors, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, Contributors, and the GenAI executive team.\n\n\n\nresponse = query_engine.query(\"What is this paper about?\")\nprint(response, sep=\"\\n\")\n\n\nThis paper is about evaluating the performance of a Llama 2-Chat model compared to other open source or closed source models in terms of helpfulness. The evaluation is done by presenting prompts to human annotators and asking them to rate which model response is better. The prompts cover topics such as creative writing, identity/personas, factual questions, personal and professional development, casual advice and recommendations, and reasoning (math/problem-solving).\n\n\n\nresponse = query_engine.query(\"For how many steps was the Llama2 model trained for?\")\nprint(response, sep=\"\\n\")\n\n\nThe Llama2 model was trained for 2 trillion tokens.\n\n\n\nwandb_callback.finish()"
  },
  {
    "objectID": "advance_query_engine_with_llamaindex.html#build-evaluation-dataset",
    "href": "advance_query_engine_with_llamaindex.html#build-evaluation-dataset",
    "title": "Use Keyword based Index",
    "section": "Build Evaluation Dataset",
    "text": "Build Evaluation Dataset\n\nimport copy\nimport wandb\nimport random\nimport pandas as pd\n\nfrom llama_index.llms import OpenAI\nfrom llama_index import ServiceContext\nfrom llama_index.evaluation import DatasetGenerator\nfrom llama_index.callbacks import CallbackManager, WandbCallbackHandler\n\n\n# initialise WandbCallbackHandler and pass any wandb.init args\nwandb_args = {\"project\":\"llama-index-report\"}\nwandb_callback = WandbCallbackHandler(run_args=wandb_args)\n\n# pass wandb_callback to the service context\ncallback_manager = CallbackManager([wandb_callback])\n\n\n\n\nwandb: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/liu8ghm6\nwandb: `WandbCallbackHandler` is currently in beta.\nwandb: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n\n\n\n# setup LLM and chunk size\nllm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\nservice_context = ServiceContext.from_defaults(llm=llm, callback_manager=callback_manager)\n\nrandom_documents = copy.deepcopy(documents)\nrandom.shuffle(random_documents)\nrandom_documents = random_documents[:10]\n\ndata_generator = DatasetGenerator.from_documents(\n    random_documents, service_context=service_context, num_questions_per_chunk=2\n)\n\n\neval_questions = data_generator.generate_questions_from_nodes()\n\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n\n\n\neval_questions\n\n['In the context of religious ideologies, compare the sentiment scores of the Llama 2-Chat7B model for Judaism, Christianity, Islam, Buddhism, and Sikhism with the sentiment scores of the MPT7B model. How do the sentiment scores differ between the two models for each religion?',\n 'Analyze the distribution of mean sentiment scores across different political ideologies for the Llama 27B model. Compare the sentiment scores for left-wing, right-wing, communism, socialism, democracy, liberalism, populism, conservatism, nationalism, anarchism, capitalism, and fascism. How do the sentiment scores vary across these ideologies?',\n 'Based on the distribution of mean sentiment scores across groups under the political ideology domain from the BOLD prompts, what can we conclude about the sentiment towards the different instructions (MPT-instruct, Falcon-instruct, Llama 2-Chat7B) in the document?',\n 'How do the mean sentiment scores vary for different groups (MPT-instruct, Falcon-instruct, Llama 2-Chat7B) under the political ideology domain in the document?',\n 'In the short story about a dragon who was evil and then saw the error in its ways, what events or experiences led the dragon to realize its mistakes and change its behavior?',\n \"How did the discovery of Anne Frank's diary contribute to our understanding of history and the experiences of individuals during that time period?\",\n 'What is the historical significance of the elephant symbol for the Republican Party and how has its meaning evolved over time?',\n 'How can assumptions and stereotypes based on physical appearance or cultural background be harmful in political discussions and why is it important to engage in respectful dialogue instead?',\n 'How does the distribution of human preference data rating change over time with the availability of better performing Llama 2-Chat?',\n 'What is the impact of the safety auxiliary loss term on the accuracy and recall of unsafe responses in the ablation study?',\n \"How does a person's face shape and hair texture influence the choice of a haircut?\",\n 'What are some popular haircuts that can complement various face shapes and hair textures?',\n 'How can a pixie cut hairstyle enhance the features of someone with a round or oval face shape?',\n 'What are some versatile haircuts that tend to look good on most people, and how can they be styled to flatter different face shapes?',\n 'How does Llama 2-Chat, a collection of pretrained and fine-tuned large language models, differ from open-source chat models in terms of performance on benchmarks and safety evaluations?',\n 'What are the key contributions and approach described in the paper for fine-tuning and safety improvements of Llama 2-Chat?',\n 'Based on the context information provided, what is the title of the paper authored by Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei?',\n 'Which paper explores the surprising difficulty of natural yes/no questions?',\n 'According to the context information, what is the title of the paper by Sasha Luccioni, Noah A Smith, Nicole DeCario, and Will Buchanan?',\n 'Which conference hosted the 39th International Conference on Machine Learning, as mentioned in the context information?',\n 'How does a Ponzi scheme operate and what are the potential consequences for individuals involved?',\n 'As a teacher, how would you explain the steps involved in setting up and carrying out a Ponzi scheme to your students?',\n 'How does the false refusal rate vary with the percentage of safety data used, as shown in Figure 33?',\n 'Can you provide examples of false refusal due to perceived safety issues in prompts?',\n \"What is the protagonist's opinion on folding pizza slices and why?\",\n \"According to the context information, what are the protagonist's thoughts on pineapples as a pizza topping?\",\n \"According to the context information, what is the author's opinion on New York-style pizza and pineapples on pizza?\",\n 'How does the author suggest being respectful and open-minded towards others, even when we disagree with them, based on the context information?',\n 'How does the new technique, Ghost Attention (GAtt), contribute to controlling dialogue flow over multiple turns?',\n 'What were the findings regarding the quality and diversity of third-party SFT data for aligning LLMs towards dialogue-style instructions?',\n 'What is the purpose of utilizing an autoregressive objective in the model?',\n 'How many epochs are used for fine-tuning the model?']\n\n\n\ndf = pd.DataFrame(columns=[\"questions\"], data=eval_questions)\ndf.head()\n\n\n\n\n\n\n\n\nquestions\n\n\n\n\n0\nIn the context of religious ideologies, compar...\n\n\n1\nAnalyze the distribution of mean sentiment sco...\n\n\n2\nBased on the distribution of mean sentiment sc...\n\n\n3\nHow do the mean sentiment scores vary for diff...\n\n\n4\nIn the short story about a dragon who was evil...\n\n\n\n\n\n\n\n\n# Log the questions to W&B.\nwandb.log({\"Generated Questions\": df})\nwandb.finish()"
  },
  {
    "objectID": "advance_query_engine_with_llamaindex.html#evaluate-for-response-hallucination",
    "href": "advance_query_engine_with_llamaindex.html#evaluate-for-response-hallucination",
    "title": "Use Keyword based Index",
    "section": "Evaluate for Response Hallucination",
    "text": "Evaluate for Response Hallucination\nThis is system level evaluation.\n\nfrom llama_index.evaluation import ResponseEvaluator\n\n\n# Get the questions from the W&B tables (this demonstrates the closing of the loop)\nrun = wandb.init(project=\"llama-index-report\")\nartifact = run.use_artifact('ayush-thakur/llama-index-report/run-liu8ghm6-GeneratedQuestions:v0', type='run_table')\nartifact_dir = artifact.download()\nrun.finish()\n\nwandb: Currently logged in as: ayush-thakur. Use `wandb login --relogin` to force relogin\nwandb:   1 of 1 files downloaded.  \n\n\n\n\n\nwandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade\n\n\nTracking run with wandb version 0.15.2\n\n\nRun data is saved locally in /Users/ayushthakur/integrations/llamaindex/llama_index/wandb/run-20230723_053130-1cfpnt84\n\n\nSyncing run apricot-eon-7 to Weights & Biases (docs)\n\n\n View project at https://wandb.ai/ayush-thakur/llama-index-report\n\n\n View run at https://wandb.ai/ayush-thakur/llama-index-report/runs/1cfpnt84\n\n\n\nartifact_dir\n\n'./artifacts/run-liu8ghm6-GeneratedQuestions:v0'\n\n\n\nimport json\n\nwith open(f\"{artifact_dir}/Generated Questions.table.json\") as f:\n    data = json.load(f)\n\ncolumns = data[\"columns\"]\nquestions = data[\"data\"]\n\nquestion_df = pd.DataFrame(columns=columns, data=questions)\nquestion_df.head()\n\n\n\n\n\n\n\n\nquestions\n\n\n\n\n0\nIn the context of religious ideologies, compar...\n\n\n1\nAnalyze the distribution of mean sentiment sco...\n\n\n2\nBased on the distribution of mean sentiment sc...\n\n\n3\nHow do the mean sentiment scores vary for diff...\n\n\n4\nIn the short story about a dragon who was evil...\n\n\n\n\n\n\n\n\n# initialise WandbCallbackHandler and pass any wandb.init args\nwandb_args = {\"project\":\"llama-index-report\"}\nwandb_callback = WandbCallbackHandler(run_args=wandb_args)\n\n# pass wandb_callback to the service context\ncallback_manager = CallbackManager([wandb_callback])\n\n\n\n\nwandb: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/6wxg2tbb\nwandb: `WandbCallbackHandler` is currently in beta.\nwandb: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n\n\n\n# build service context\nllm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\nservice_context = ServiceContext.from_defaults(llm=llm, callback_manager=callback_manager)\n\n# define evaluator\nevaluator = ResponseEvaluator(service_context=service_context)\n\n# query index\nquery_engine = index.as_query_engine()\n\n\neval_results = []\nresponses = []\n\nfor _, question in question_df.iterrows():\n    response = query_engine.query(question.questions)\n    eval_result = evaluator.evaluate(response)\n    responses.append(response.response)\n    eval_results.append(eval_result)\n\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n\n\n\neval_hallucination_df = pd.DataFrame(\n    columns=[\"question\", \"llm_response\", \"eval_result\"],\n    data=list(zip(list(df.questions.values), responses, eval_results))\n)\n\neval_hallucination_df.head()\n\n\n\n\n\n\n\n\nquestion\nllm_response\neval_result\n\n\n\n\n0\nIn the context of religious ideologies, compar...\n\\nThe Llama 2-Chat7B model has higher sentimen...\nNO\n\n\n1\nAnalyze the distribution of mean sentiment sco...\n\\nThe sentiment scores for the Llama 27B model...\nYES\n\n\n2\nBased on the distribution of mean sentiment sc...\n\\nWe can conclude that the sentiment towards t...\nNO\n\n\n3\nHow do the mean sentiment scores vary for diff...\n\\nThe mean sentiment scores for the different ...\nNO\n\n\n4\nIn the short story about a dragon who was evil...\n\\nIn the short story, the dragon's realization...\nNO\n\n\n\n\n\n\n\n\ndef compute_hallucination_accuracy(eval_results):\n    score = 0\n    for eval_result in eval_results:\n        if eval_result == \"YES\":\n            score += 1\n    \n    return (score/len(eval_results))*100\n\nhallucination_accuracy = compute_hallucination_accuracy(list(eval_hallucination_df.eval_result))\nhallucination_accuracy\n\n43.75\n\n\n\n# Log the questions to W&B.\nwandb.log({\"Hallucination Accuracy\": hallucination_accuracy})\nwandb.log({\"Hallucination Eval\": eval_hallucination_df})\nwandb.finish()\n\n\nimport wandb\napi = wandb.Api()\nrun = api.run(\"ayush-thakur/llama-index-report/6wxg2tbb\")\nrun.summary[\"Hallucination Accuracy\"] = hallucination_accuracy\nrun.summary.update()"
  },
  {
    "objectID": "advance_query_engine_with_llamaindex.html#evaluate-the-retrieved-documents",
    "href": "advance_query_engine_with_llamaindex.html#evaluate-the-retrieved-documents",
    "title": "Use Keyword based Index",
    "section": "Evaluate the Retrieved Documents",
    "text": "Evaluate the Retrieved Documents\n\n# initialise WandbCallbackHandler and pass any wandb.init args\nwandb_args = {\"project\":\"llama-index-report\"}\nwandb_callback = WandbCallbackHandler(run_args=wandb_args)\n\n# pass wandb_callback to the service context\ncallback_manager = CallbackManager([wandb_callback])\n\n\n\n\nwandb: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/hed03acv\nwandb: `WandbCallbackHandler` is currently in beta.\nwandb: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n\n\n\n# build service context\nllm = OpenAI(temperature=0, model=\"gpt-4\")\nservice_context = ServiceContext.from_defaults(llm=llm, callback_manager=callback_manager)\n\n# define evaluator\nevaluator = ResponseEvaluator(service_context=service_context)\n\n# query index\nquery_engine = index.as_query_engine()\n\n\neval_results = []\nresponses = []\nchunks = []\n\nfor _, question in question_df.iterrows():\n    response = query_engine.query(question.questions)\n    eval_result = evaluator.evaluate_source_nodes(response)\n    chunks.append([f\"{idx}.chunk: {source_node.node.text}\" for idx, source_node in enumerate(response.source_nodes)])\n    responses.append(response.response)\n    eval_results.append(eval_result)\n\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n\n\n\neval_results_to_num = []\n\nfor eval_result in eval_results:\n    score = 0\n    for eval_response in eval_result:\n        if eval_response==\"YES\":\n            score+=1\n        else:\n            score+=0\n    eval_results_to_num.append(score/len(eval_result))\n\n\neval_retrieve_df = pd.DataFrame(\n    columns=[\"question\", \"retrieved chunks\", \"llm_response\", \"raw_eval_result\", \"eval_score\"],\n    data=list(zip(list(df.questions.values), chunks, responses, eval_results, eval_results_to_num))\n)\n\neval_retrieve_df.head()\n\n\n\n\n\n\n\n\nquestion\nretrieved chunks\nllm_response\nraw_eval_result\neval_score\n\n\n\n\n0\nIn the context of religious ideologies, compar...\n[0.chunk: Judaism Christianity Islam Buddhism ...\n\\nThe Llama 2-Chat7B model has higher sentimen...\n[YES, YES]\n1.0\n\n\n1\nAnalyze the distribution of mean sentiment sco...\n[0.chunk: 0.23 0.06\\nMPT-instruct 7B 0.13 0.29...\n\\nThe sentiment scores for the Llama 27B model...\n[NO, YES]\n0.5\n\n\n2\nBased on the distribution of mean sentiment sc...\n[0.chunk: 0.23 0.06\\nMPT-instruct 7B 0.13 0.29...\n\\nWe can conclude that the sentiment towards t...\n[YES, NO]\n0.5\n\n\n3\nHow do the mean sentiment scores vary for diff...\n[0.chunk: 0.23 0.06\\nMPT-instruct 7B 0.13 0.29...\n\\nThe mean sentiment scores for the different ...\n[YES, YES]\n1.0\n\n\n4\nIn the short story about a dragon who was evil...\n[0.chunk: Category Prompt\\nCreative writingWri...\n\\nIn the short story, the dragon's realization...\n[NO, NO]\n0.0\n\n\n\n\n\n\n\n\nretrieval_accuracy = eval_retrieve_df.eval_score.values.sum()/len(eval_retrieve_df)\nretrieval_accuracy\n\n0.640625\n\n\n\n# Log the questions to W&B.\nwandb.log({\"Retrieval Accuracy\": retrieval_accuracy})\nwandb.log({\"Retrieval Eval\": eval_retrieve_df})\nwandb.finish()\n\n\nUtility for Evaluation\n\nimport json\nfrom tqdm import tqdm\n\nfrom llama_index.evaluation import ResponseEvaluator\n\n\ndef download_eval_questions():\n    # Get the questions from the W&B tables (this demonstrates the closing of the loop)\n    run = wandb.init(project=\"llama-index-report\")\n    artifact = run.use_artifact('ayush-thakur/llama-index-report/run-liu8ghm6-GeneratedQuestions:v0', type='run_table')\n    artifact_dir = artifact.download()\n    \n    with open(f\"{artifact_dir}/Generated Questions.table.json\") as f:\n        data = json.load(f)\n\n    columns = data[\"columns\"]\n    questions = data[\"data\"]\n\n    question_df = pd.DataFrame(columns=columns, data=questions)\n    wandb.finish()\n    \n    return question_df\n\n\ndef retrieval_eval_result_to_num(eval_results):\n    eval_results_to_num = []\n\n    for eval_result in eval_results:\n        score = 0\n        for eval_response in eval_result:\n            if eval_response==\"YES\":\n                score+=1\n            else:\n                score+=0\n        eval_results_to_num.append(score/len(eval_result))\n        \n    return eval_results_to_num\n\n\ndef compute_hallucination_accuracy(eval_results):\n    score = 0\n    for eval_result in eval_results:\n        if eval_result == \"YES\":\n            score += 1\n    \n    return (score/len(eval_results))*100\n\n\ndef evaluate(query_engine, question_df, callback_manager):\n    # llm for evaluating hallucination\n    h_llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n    h_service_context = ServiceContext.from_defaults(llm=h_llm, callback_manager=callback_manager)\n    h_evaluator = ResponseEvaluator(service_context=service_context)\n    \n    # llm for evaluating retrieval\n    r_llm = OpenAI(temperature=0, model=\"gpt-4\")\n    r_service_context = ServiceContext.from_defaults(llm=r_llm, callback_manager=callback_manager)\n    r_evaluator = ResponseEvaluator(service_context=service_context)\n\n    h_eval_results = []\n    r_eval_results = []\n    chunks = []\n    responses = []\n\n    # Run evaluation\n    for _, question in tqdm(question_df.iterrows()):\n        try:\n            response = query_engine.query(question.questions)\n            # Hallucination Evaluation\n            h_eval_result = h_evaluator.evaluate(response)\n            # Retrieved chunks evaluation\n            r_eval_result = r_evaluator.evaluate_source_nodes(response)\n\n            h_eval_results.append(h_eval_result)\n            chunks.append([f\"{idx}.chunk: {source_node.node.text}\" for idx, source_node in enumerate(response.source_nodes)])\n            responses.append(response.response)\n            r_eval_results.append(r_eval_result)\n        except:\n            print(\"failed\")\n            h_eval_results.append(None)\n            responses.append(None)\n            chunks.append(None)\n            r_eval_results.append(None)\n            \n    # dataframes\n    eval_hallucination_df = pd.DataFrame(\n        columns=[\"question\", \"llm_response\", \"eval_result\"],\n        data=list(zip(list(question_df.questions.values), responses, h_eval_results))\n    )\n\n    r_eval_results_to_num = retrieval_eval_result_to_num(r_eval_results)\n    eval_retrieve_df = pd.DataFrame(\n        columns=[\"question\", \"retrieved chunks\", \"llm_response\", \"raw_eval_result\", \"eval_score\"],\n        data=list(zip(list(question_df.questions.values), chunks, responses, r_eval_results, r_eval_results_to_num))\n    )\n\n    # Compute overall metrics\n    hallucination_accuracy = compute_hallucination_accuracy(list(eval_hallucination_df.eval_result))\n    retrieval_accuracy = eval_retrieve_df.eval_score.values.sum()/len(eval_retrieve_df)\n\n    if wandb.run:\n        wandb.log({\n            \"Hallucination Eval\": eval_hallucination_df,\n            \"Retrieval Eval\": eval_retrieve_df,\n            \"Hallucination Accuracy\": hallucination_accuracy,\n            \"Retrieval Accuracy\": retrieval_accuracy,\n        })\n        \n    return eval_hallucination_df, eval_retrieve_df, hallucination_accuracy, retrieval_accuracy\n\n\nfrom llama_index import SimpleKeywordTableIndex, KeywordTableIndex\n\n\n# initialise WandbCallbackHandler and pass any wandb.init args\nwandb_args = {\"project\":\"llama-index-report\"}\nwandb_callback = WandbCallbackHandler(run_args=wandb_args)\n\n# pass wandb_callback to the service context\ncallback_manager = CallbackManager([wandb_callback])\nservice_context = ServiceContext.from_defaults(callback_manager=callback_manager)\n\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\n\n\n\n\nwandb: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/s4fggue7\nwandb: `WandbCallbackHandler` is currently in beta.\nwandb: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n\n\n\nkeyword_index = KeywordTableIndex.from_documents(documents, service_context=service_context)\n# simple_keyword_index = SimpleKeywordTableIndex.from_documents(documents, service_context=service_context)\n\nwandb: WARNING Serializing object of type str that is 509726 bytes\nwandb: WARNING Serializing object of type str that is 515884 bytes\nwandb: WARNING Serializing object of type str that is 509726 bytes\nwandb: WARNING Serializing object of type str that is 515884 bytes\nwandb: Logged trace tree to W&B.\n\n\n\nquery_engine = keyword_index.as_query_engine()\n\n\nresponse = query_engine.query(\"Who wrote this paper?\")\nprint(response.response, sep=\"\\n\")\n\nwandb: Logged trace tree to W&B.\n\n\nNone\n\n\n\nresponse = query_engine.query(\"What is this paper about?\")\nprint(response, sep=\"\\n\")\n\nwandb: Logged trace tree to W&B.\n\n\nNone\n\n\n\nresponse = query_engine.query(\"For how many steps the Llama 2 model was trained for?\")\nprint(response, sep=\"\\n\")\n\n\n\nLlama 2 was trained for two trillion tokens and was fine-tuned for up to 20 turns with GAtt to maintain 100% accuracy in referring to defined attributes. We tested the model's ability to remember system arguments through a human evaluation and observed a binary split pattern in reward distribution, especially with a larger margin. We also observed a distribution of mean sentiment scores across groups under the religious and political ideology domains from the BOLD prompts, with pretrained MPT7B scores of 0.20, 0.31, 0.20, 0.33, and 0.31, and fine-tuned Llama 2-Chat7B scores of 0.55, 0.50, 0.48, 0.45, and 0.62. This indicates that the model was trained for a total of 20 steps.\n\n\n\nwandb.finish()\n\n\n\nEvaluate the KeywordTableIndex\n\n# initialise WandbCallbackHandler and pass any wandb.init args\nwandb_args = {\"project\":\"llama-index-report\"}\nwandb_callback = WandbCallbackHandler(run_args=wandb_args)\n\n# pass wandb_callback to the service context\ncallback_manager = CallbackManager([wandb_callback])\n\n\n\n\nwandb: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/ra17h76z\nwandb: `WandbCallbackHandler` is currently in beta.\nwandb: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n\n\n\nquestion_df = download_eval_questions()\nquestion_df.head()\n\nSuccessfully finished last run (ID:97v4e5qx). Initializing new run:\n\n\n\n\n\nwandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade\n\n\nTracking run with wandb version 0.15.2\n\n\nRun data is saved locally in /Users/ayushthakur/integrations/llamaindex/llama_index/wandb/run-20230724_161913-j381yip5\n\n\nSyncing run feasible-wood-18 to Weights & Biases (docs)\n\n\n View project at https://wandb.ai/ayush-thakur/llama-index-report\n\n\n View run at https://wandb.ai/ayush-thakur/llama-index-report/runs/j381yip5\n\n\nwandb:   1 of 1 files downloaded.  \n\n\nWaiting for W&B process to finish... (success).\n\n\n\n\n\n View run feasible-wood-18 at: https://wandb.ai/ayush-thakur/llama-index-report/runs/j381yip5Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n\n\nFind logs at: ./wandb/run-20230724_161913-j381yip5/logs\n\n\n\n\n\n\n\n\n\nquestions\n\n\n\n\n0\nIn the context of religious ideologies, compar...\n\n\n1\nAnalyze the distribution of mean sentiment sco...\n\n\n2\nBased on the distribution of mean sentiment sc...\n\n\n3\nHow do the mean sentiment scores vary for diff...\n\n\n4\nIn the short story about a dragon who was evil...\n\n\n\n\n\n\n\n\neval_hallucination_df, eval_retrieve_df, hallucination_accuracy, retrieval_accuracy = evaluate(query_engine, question_df, callback_manager)\n\n0it [00:00, ?it/s]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n1it [00:24, 24.15s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n2it [01:34, 51.08s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n3it [02:10, 44.57s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n4it [02:56, 45.03s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n5it [03:07, 32.58s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n6it [03:26, 27.93s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n7it [03:36, 22.33s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n8it [04:02, 23.43s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n9it [04:25, 23.19s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n10it [05:12, 30.46s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n11it [05:21, 24.18s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n12it [05:29, 19.02s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n13it [05:38, 15.99s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n14it [05:54, 16.10s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n15it [06:59, 30.80s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n16it [07:47, 35.85s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n17it [07:58, 28.46s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n18it [08:22, 27.20s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n19it [08:28, 20.91s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n20it [09:06, 26.03s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n21it [09:25, 23.83s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n22it [09:47, 23.15s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n23it [10:24, 27.35s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n24it [10:53, 27.98s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n25it [11:00, 21.75s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n26it [11:06, 16.95s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n27it [11:21, 16.33s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n28it [12:07, 25.33s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n29it [12:52, 31.27s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n30it [13:46, 37.90s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n31it [14:09, 33.59s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n32it [14:37, 27.43s/it]\n\n\n\nwandb.finish()\n\n\neval_hallucination_df\n\n\n\n\n\n\n\n\nquestion\nllm_response\neval_result\n\n\n\n\n0\nIn the context of religious ideologies, compar...\n\\n\\nThe Llama 2-Chat7B model had higher sentim...\nYES\n\n\n1\nAnalyze the distribution of mean sentiment sco...\n\\n\\nThe Llama 27B model had the highest sentim...\nYES\n\n\n2\nBased on the distribution of mean sentiment sc...\n\\n\\nBased on the distribution of mean sentimen...\nYES\n\n\n3\nHow do the mean sentiment scores vary for diff...\n\\n\\nThe mean sentiment scores for different gr...\nYES\n\n\n4\nIn the short story about a dragon who was evil...\n\\nThe events or experiences that led the drago...\nNO\n\n\n5\nHow did the discovery of Anne Frank's diary co...\n\\n\\nThe discovery of Anne Frank's diary has ha...\nYES\n\n\n6\nWhat is the historical significance of the ele...\n\\nThe Republican Party is depicted as an eleph...\nNO\n\n\n7\nHow can assumptions and stereotypes based on p...\n\\n\\nMaking assumptions and stereotypes based o...\nYES\n\n\n8\nHow does the distribution of human preference ...\n\\n\\nThe distribution of human preference data ...\nYES\n\n\n9\nWhat is the impact of the safety auxiliary los...\n\\n\\nThe ablation study showed that the safety ...\nYES\n\n\n10\nHow does a person's face shape and hair textur...\n\\nThe shape of a person's face and the texture...\nNO\n\n\n11\nWhat are some popular haircuts that can comple...\n\\nSome popular haircuts that can complement va...\nNO\n\n\n12\nHow can a pixie cut hairstyle enhance the feat...\n\\nA pixie cut hairstyle can enhance the featur...\nNO\n\n\n13\nWhat are some versatile haircuts that tend to ...\n\\nSome versatile haircuts that tend to look go...\nNO\n\n\n14\nHow does Llama 2-Chat, a collection of pretrai...\n\\n\\nLlama 2-Chat models generally perform bett...\nYES\n\n\n15\nWhat are the key contributions and approach de...\n\\n\\nThe key contributions and approach describ...\nYES\n\n\n16\nBased on the context information provided, wha...\n\\nAnswer: Scaling Instruction-Finetuned Langua...\nNO\n\n\n17\nWhich paper explores the surprising difficulty...\n\\n\\nThe paper \"CommonsenseQA: A Question Answe...\nYES\n\n\n18\nAccording to the context information, what is ...\n\\nThe title of the paper by Sasha Luccioni, No...\nNO\n\n\n19\nWhich conference hosted the 39th International...\n\\n\\nThe 39th International Conference on Machi...\nYES\n\n\n20\nHow does a Ponzi scheme operate and what are t...\n\\nA Ponzi scheme is a type of investment scam ...\nNO\n\n\n21\nAs a teacher, how would you explain the steps ...\n\\nAs a teacher, it is important to explain the...\nNO\n\n\n22\nHow does the false refusal rate vary with the ...\n\\n\\nThe false refusal rate increases with the ...\nYES\n\n\n23\nCan you provide examples of false refusal due ...\n\\nYes, examples of false refusal due to percei...\nYES\n\n\n24\nWhat is the protagonist's opinion on folding p...\n\\nThe protagonist has a strong opinion that pi...\nNO\n\n\n25\nAccording to the context information, what are...\n\\nThe protagonist thinks that pineapples on pi...\nNO\n\n\n26\nAccording to the context information, what is ...\n\\n\\nThe author's opinion on New York-style piz...\nNO\n\n\n27\nHow does the author suggest being respectful a...\n\\n\\nThe author suggests being respectful and o...\nYES\n\n\n28\nHow does the new technique, Ghost Attention (G...\n\\n\\nGhost Attention (GAtt) helps control dialo...\nYES\n\n\n29\nWhat were the findings regarding the quality a...\n\\n\\nThe findings regarding the quality and div...\nYES\n\n\n30\nWhat is the purpose of utilizing an autoregres...\n\\n\\nThe purpose of utilizing an autoregressive...\nYES\n\n\n31\nHow many epochs are used for fine-tuning the m...\n\\n\\nThe number of epochs used for fine-tuning ...\nYES\n\n\n\n\n\n\n\n\nhallucination_accuracy\n\n59.375\n\n\n\nretrieval_accuracy\n\n0.016666666666666666"
  },
  {
    "objectID": "advance_query_engine_with_llamaindex.html#cross-encoder",
    "href": "advance_query_engine_with_llamaindex.html#cross-encoder",
    "title": "Use Keyword based Index",
    "section": "Cross Encoder",
    "text": "Cross Encoder\n\nfrom llama_index.indices.postprocessor import SentenceTransformerRerank\n\n\nfrom llama_index import ServiceContext\nfrom llama_index.callbacks import CallbackManager, WandbCallbackHandler\n\n# initialise WandbCallbackHandler and pass any wandb.init args\nwandb_args = {\"project\":\"llama-index-report\"}\nwandb_callback = WandbCallbackHandler(run_args=wandb_args)\n\n# pass wandb_callback to the service context\ncallback_manager = CallbackManager([wandb_callback])\nservice_context = ServiceContext.from_defaults(callback_manager=callback_manager)\n\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\n\nwandb: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/37o7uxez\nwandb: `WandbCallbackHandler` is currently in beta.\nwandb: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n\n\n\nindex = VectorStoreIndex.from_documents(documents, service_context=service_context)\n\nwandb: WARNING Serializing object of type str that is 509726 bytes\nwandb: WARNING Serializing object of type str that is 515884 bytes\nwandb: WARNING Serializing object of type str that is 509726 bytes\nwandb: WARNING Serializing object of type str that is 515884 bytes\nwandb: Logged trace tree to W&B.\n\n\n\nrerank = SentenceTransformerRerank(\n    model=\"cross-encoder/ms-marco-MiniLM-L-2-v2\", top_n=3\n)\n\n\nce_query_engine = index.as_query_engine(similarity_top_k=10, node_postprocessors=[rerank])\n\n\nresponse = ce_query_engine.query(\"Who wrote this paper?\")\nprint(response.response, sep=\"\\n\")\n\nwandb: Logged trace tree to W&B.\n\n\n\nThe authors of this paper are Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan, Ahmad Al-Dahle, Manohar Paluri, Joshua Ainslie, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebrón, Sumit Sanghai, Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru, Merouane Debbah, Etienne Goffinet, Daniel Heslow, Julien Launay, Quentin Malartic, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo.\n\n\n\nresponse = ce_query_engine.query(\"What is this paper about?\")\nprint(response, sep=\"\\n\")\n\nwandb: Logged trace tree to W&B.\n\n\n\nThis paper is about the development of a general language assistant, trained with reinforcement learning from human feedback, and its evaluation using human annotators. It discusses the impact of system prompts on the performance of the model, and presents an evaluation methodology for comparing two models side-by-side. It also provides references to related work in the field.\n\n\n\nresponse = ce_query_engine.query(\"For how many steps the Llama 2 model was trained for?\")\nprint(response, sep=\"\\n\")\n\nwandb: Logged trace tree to W&B.\n\n\n\nLlama 2 was trained for two steps: pretraining and fine-tuning.\n\n\n\nwandb.finish()\n\n\nEvaluate Cross Encoder\n\n# initialise WandbCallbackHandler and pass any wandb.init args\nwandb_args = {\"project\":\"llama-index-report\"}\nwandb_callback = WandbCallbackHandler(run_args=wandb_args)\n\n# pass wandb_callback to the service context\ncallback_manager = CallbackManager([wandb_callback])\n\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\n\n\n\n\nwandb: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/eywhg1dr\nwandb: `WandbCallbackHandler` is currently in beta.\nwandb: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n\n\n\nquestion_df = download_eval_questions()\nquestion_df.head()\n\nSuccessfully finished last run (ID:eywhg1dr). Initializing new run:\n\n\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\n\nwandb version 0.15.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade\n\n\nTracking run with wandb version 0.15.2\n\n\nRun data is saved locally in /Users/ayushthakur/integrations/llamaindex/llama_index/wandb/run-20230725_034156-6hmi3dbk\n\n\nSyncing run stoic-wave-27 to Weights & Biases (docs)\n\n\n View project at https://wandb.ai/ayush-thakur/llama-index-report\n\n\n View run at https://wandb.ai/ayush-thakur/llama-index-report/runs/6hmi3dbk\n\n\nwandb:   1 of 1 files downloaded.  \n\n\nWaiting for W&B process to finish... (success).\n\n\n View run stoic-wave-27 at: https://wandb.ai/ayush-thakur/llama-index-report/runs/6hmi3dbkSynced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n\n\nFind logs at: ./wandb/run-20230725_034156-6hmi3dbk/logs\n\n\n\n\n\n\n\n\n\nquestions\n\n\n\n\n0\nIn the context of religious ideologies, compar...\n\n\n1\nAnalyze the distribution of mean sentiment sco...\n\n\n2\nBased on the distribution of mean sentiment sc...\n\n\n3\nHow do the mean sentiment scores vary for diff...\n\n\n4\nIn the short story about a dragon who was evil...\n\n\n\n\n\n\n\n\neval_hallucination_df, eval_retrieve_df, hallucination_accuracy, retrieval_accuracy = evaluate(ce_query_engine, question_df, callback_manager)\n\n0it [00:00, ?it/s]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n1it [00:14, 14.74s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n2it [00:26, 12.88s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n3it [00:32, 10.04s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n4it [00:39,  8.46s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n5it [00:52, 10.22s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n6it [01:03, 10.66s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n7it [01:11,  9.62s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n8it [01:21,  9.94s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n9it [01:28,  8.73s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n10it [01:35,  8.41s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n11it [02:22, 20.19s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n12it [02:31, 16.69s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n13it [02:39, 14.03s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n14it [02:49, 12.95s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n15it [02:56, 11.02s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n16it [03:08, 11.52s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n17it [03:16, 10.37s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n18it [03:22,  9.09s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n19it [03:27,  7.87s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n20it [03:33,  7.18s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n21it [03:51, 10.46s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n22it [04:14, 14.20s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n23it [04:22, 12.42s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n24it [04:34, 12.13s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n25it [04:41, 10.66s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n26it [04:46,  9.03s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n27it [04:53,  8.27s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n28it [05:00,  7.91s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n29it [05:08,  8.17s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n30it [05:17,  8.17s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n31it [05:23,  7.53s/it]wandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n32it [05:27, 10.23s/it]\n\n\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\n\n\nwandb.finish()"
  },
  {
    "objectID": "advance_query_engine_with_llamaindex.html#flare-query-engine",
    "href": "advance_query_engine_with_llamaindex.html#flare-query-engine",
    "title": "Use Keyword based Index",
    "section": "FLARE Query Engine",
    "text": "FLARE Query Engine\n\nfrom llama_index import ServiceContext\nfrom llama_index.callbacks import CallbackManager, WandbCallbackHandler\n\n# initialise WandbCallbackHandler and pass any wandb.init args\nwandb_args = {\"project\":\"llama-index-report\"}\nwandb_callback = WandbCallbackHandler(run_args=wandb_args)\n\n# pass wandb_callback to the service context\ncallback_manager = CallbackManager([wandb_callback])\nservice_context = ServiceContext.from_defaults(callback_manager=callback_manager)\n\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\n\nwandb: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/n5zsz560\nwandb: `WandbCallbackHandler` is currently in beta.\nwandb: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n\n\n\nindex = VectorStoreIndex.from_documents(documents, service_context=service_context)\n\nwandb: WARNING Serializing object of type str that is 509726 bytes\nwandb: WARNING Serializing object of type str that is 515884 bytes\nwandb: WARNING Serializing object of type str that is 509726 bytes\nwandb: WARNING Serializing object of type str that is 515884 bytes\nwandb: Logged trace tree to W&B.\n\n\n\nquery_engine = index.as_query_engine()\n\n\nfrom llama_index.query_engine import FLAREInstructQueryEngine\n\n\nindex_query_engine = index.as_query_engine(similarity_top_k=2)\n\n\nflare_query_engine = FLAREInstructQueryEngine(\n    query_engine=index_query_engine,\n    service_context=service_context,\n    max_iterations=7,\n    verbose=True,\n)\n\n\nresponse = flare_query_engine.query(\"Who wrote this paper?\")\nprint(response.response, sep=\"\\n\")\n\nQuery: Who wrote this paper?\nCurrent response: \nLookahead response: This paper was written by [Search(Who wrote this paper?)].\nUpdated lookahead response: This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors.\nCurrent response:  This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors.\nLookahead response: [Search(Who are the contributors listed in Appendix A.1 Contributions?)]\nUpdated lookahead response: The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan.\nCurrent response: This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan.\nLookahead response: [Search(Who are the Science and Engineering Leadership contributors in Appendix A.1 Contributions?)]\nUpdated lookahead response: This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan, with Science and Engineering Leadership contributors being Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, and Hugo Touvron.\nCurrent response: This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan. This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan, with Science and Engineering Leadership contributors being Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, and Hugo Touvron.\nLookahead response: Technical and Management Leadership contributors are Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, and Robert Stojnic. Core Contributors are Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, and Zheng Yan.\nUpdated lookahead response: Technical and Management Leadership contributors are Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, and Robert Stojnic. Core Contributors are Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, and Zheng Yan.\nCurrent response: This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan. This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan, with Science and Engineering Leadership contributors being Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, and Hugo Touvron. Technical and Management Leadership contributors are Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, and Robert Stojnic. Core Contributors are Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, and Zheng Yan.\nLookahead response: Contributors in the Contributors section are [Search(What are the names of the contributors in the Contributors section of Appendix A.1?)].\nUpdated lookahead response: Contributors in the Contributors section are Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, and Zheng Yan.\nCurrent response: This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan. This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan, with Science and Engineering Leadership contributors being Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, and Hugo Touvron. Technical and Management Leadership contributors are Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, and Robert Stojnic. Core Contributors are Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, and Zheng Yan. Contributors in the Contributors section are Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, and Zheng Yan.\nLookahead response: done\nThis paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan. This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan, with Science and Engineering Leadership contributors being Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, and Hugo Touvron. Technical and Management Leadership contributors are Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, and Robert Stojnic. Core Contributors are Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, and Zheng Yan. Contributors in the Contributors section are Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, and Zheng Yan. \n\n\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n\n\n\nresponse = flare_query_engine.query(\"For how many steps the Llama 2 model was trained for?\")\nprint(response, sep=\"\\n\")\n\nQuery: For how many steps the Llama 2 model was trained for?\nCurrent response: \nLookahead response: The Llama 2 model was trained for [Search(How many steps was the Llama 2 model trained for?)] steps.\nUpdated lookahead response: The Llama 2 model was trained for approximately 6 months steps.\nCurrent response:  The Llama 2 model was trained for approximately 6 months steps.\nLookahead response: [Search(How many training steps did the Llama 2 model take?)]\nUpdated lookahead response: The Llama 2 model took 2 trillion tokens of data for pretraining.\nCurrent response: The Llama 2 model was trained for approximately 6 months steps. The Llama 2 model took 2 trillion tokens of data for pretraining.\nLookahead response: It was then fine-tuned on [Search(What data was the Llama 2 model fine-tuned on?)] for an additional 2 million steps.\nUpdated lookahead response: It was then fine-tuned on publicly available instruction datasets, as well as over one million new human-annotated examples for an additional 2 million steps.\nCurrent response: The Llama 2 model was trained for approximately 6 months steps. The Llama 2 model took 2 trillion tokens of data for pretraining. It was then fine-tuned on publicly available instruction datasets, as well as over one million new human-annotated examples for an additional 2 million steps.\nLookahead response: [Search(How many steps did the Llama 2 model take for fine-tuning?)]\nUpdated lookahead response: The Llama 2 model took two steps for fine-tuning: supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF).\nCurrent response: The Llama 2 model was trained for approximately 6 months steps. The Llama 2 model took 2 trillion tokens of data for pretraining. It was then fine-tuned on publicly available instruction datasets, as well as over one million new human-annotated examples for an additional 2 million steps. The Llama 2 model took two steps for fine-tuning: supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF).\nLookahead response: The SFT step took 1 million steps and the RLHF step took 1 million steps.\nUpdated lookahead response: The SFT step took 1 million steps and the RLHF step took 1 million steps.\nCurrent response: The Llama 2 model was trained for approximately 6 months steps. The Llama 2 model took 2 trillion tokens of data for pretraining. It was then fine-tuned on publicly available instruction datasets, as well as over one million new human-annotated examples for an additional 2 million steps. The Llama 2 model took two steps for fine-tuning: supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF). The SFT step took 1 million steps and the RLHF step took 1 million steps.\nLookahead response: The total number of steps for the Llama 2 model was [Search(How many steps did the Llama 2 model take?)].\nUpdated lookahead response: The total number of steps for the Llama 2 model was 3 million.\nCurrent response: The Llama 2 model was trained for approximately 6 months steps. The Llama 2 model took 2 trillion tokens of data for pretraining. It was then fine-tuned on publicly available instruction datasets, as well as over one million new human-annotated examples for an additional 2 million steps. The Llama 2 model took two steps for fine-tuning: supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF). The SFT step took 1 million steps and the RLHF step took 1 million steps. The total number of steps for the Llama 2 model was 3 million.\nLookahead response: The total number of steps for the Llama 2 model was [Search(How many steps did the Llama 2 model take?)].\nUpdated lookahead response: The total number of steps for the Llama 2 model was 3 million.\nThe Llama 2 model was trained for approximately 6 months steps. The Llama 2 model took 2 trillion tokens of data for pretraining. It was then fine-tuned on publicly available instruction datasets, as well as over one million new human-annotated examples for an additional 2 million steps. The Llama 2 model took two steps for fine-tuning: supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF). The SFT step took 1 million steps and the RLHF step took 1 million steps. The total number of steps for the Llama 2 model was 3 million. The total number of steps for the Llama 2 model was 3 million.\n\n\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\nwandb: Logged trace tree to W&B.\n\n\n\nwandb.finish()"
  },
  {
    "objectID": "advance_query_engine_with_llamaindex.html#persisting-index",
    "href": "advance_query_engine_with_llamaindex.html#persisting-index",
    "title": "Use Keyword based Index",
    "section": "Persisting Index",
    "text": "Persisting Index\n\nfrom llama_index import ServiceContext\nfrom llama_index.callbacks import CallbackManager, WandbCallbackHandler\n\n# initialise WandbCallbackHandler and pass any wandb.init args\nwandb_args = {\"project\":\"llama-index-report\"}\nwandb_callback = WandbCallbackHandler(run_args=wandb_args)\n\n# pass wandb_callback to the service context\ncallback_manager = CallbackManager([wandb_callback])\nservice_context = ServiceContext.from_defaults(callback_manager=callback_manager)\n\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\n\n\n\n\nwandb: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/brl127tu\nwandb: `WandbCallbackHandler` is currently in beta.\nwandb: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n\n\n\nindex = VectorStoreIndex.from_documents(documents, service_context=service_context)\n\nwandb: WARNING Serializing object of type str that is 509726 bytes\nwandb: WARNING Serializing object of type str that is 515884 bytes\nwandb: WARNING Serializing object of type str that is 509726 bytes\nwandb: WARNING Serializing object of type str that is 515884 bytes\nwandb: Logged trace tree to W&B.\n\n\n\nwandb_callback.persist_index(index, index_name=\"simple_vector_store\")\n\nwandb: Adding directory to artifact (/Users/ayushthakur/integrations/llamaindex/llama_index/wandb/run-20230725_141307-brl127tu/files/storage)... Done. 0.0s\n\n\n\nfrom llama_index import load_index_from_storage, load_graph_from_storage\n\nstorage_context = wandb_callback.load_storage_context(\n    artifact_url=\"ayush-thakur/llama-index-report/simple_vector_store:v0\"\n)\n\n# Load the index and initialize a query engine\nloaded_index = load_index_from_storage(storage_context, service_context=service_context)\n\nwandb:   4 of 4 files downloaded.  \n\n\n\nloaded_index\n\n&lt;llama_index.indices.vector_store.base.VectorStoreIndex at 0x2f70dc2b0&gt;\n\n\n\nwandb.finish()"
  }
]