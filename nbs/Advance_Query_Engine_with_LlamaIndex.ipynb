{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e243176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ayushthakur/integrations/llamaindex/llama_index\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19739973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.10.post1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import llama_index\n",
    "print(llama_index.__version__)\n",
    "from llama_index import VectorStoreIndex\n",
    "from llama_index import download_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85184bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"/Users/ayushthakur/integrations/llamaindex/apis.env\")\n",
    "\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5df2268",
   "metadata": {},
   "source": [
    "## Simple Query Engine\n",
    "\n",
    "To set benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c587d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDFReader = download_loader(\"PDFReader\")\n",
    "\n",
    "loader = PDFReader()\n",
    "documents = loader.load_data(file=Path('../llama2.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b667b9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/v7h22l9i\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbCallbackHandler` is currently in beta.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n"
     ]
    }
   ],
   "source": [
    "from llama_index import ServiceContext\n",
    "from llama_index.callbacks import CallbackManager, WandbCallbackHandler\n",
    "\n",
    "# initialise WandbCallbackHandler and pass any wandb.init args\n",
    "wandb_args = {\"project\":\"llama-index-report\"}\n",
    "wandb_callback = WandbCallbackHandler(run_args=wandb_args)\n",
    "\n",
    "# pass wandb_callback to the service context\n",
    "callback_manager = CallbackManager([wandb_callback])\n",
    "service_context = ServiceContext.from_defaults(callback_manager=callback_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ed8c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7d9410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f401056d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This paper was written by a large group of contributors, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, Contributors, and the GenAI executive team.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Who wrote this paper?\")\n",
    "print(response, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d282ab7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This paper is about evaluating the performance of a Llama 2-Chat model compared to other open source or closed source models in terms of helpfulness. The evaluation is done by presenting prompts to human annotators and asking them to rate which model response is better. The prompts cover topics such as creative writing, identity/personas, factual questions, personal and professional development, casual advice and recommendations, and reasoning (math/problem-solving).\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is this paper about?\")\n",
    "print(response, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccc6d61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Llama2 model was trained for 2 trillion tokens.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"For how many steps was the Llama2 model trained for?\")\n",
    "print(response, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "264c4f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_callback.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f5dc0c",
   "metadata": {},
   "source": [
    "## Build Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78430fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import wandb\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.evaluation import DatasetGenerator\n",
    "from llama_index.callbacks import CallbackManager, WandbCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "014ed47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e65db2f3d904b9397bbc31daaf1d5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016713924299983772, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/liu8ghm6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbCallbackHandler` is currently in beta.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n"
     ]
    }
   ],
   "source": [
    "# initialise WandbCallbackHandler and pass any wandb.init args\n",
    "wandb_args = {\"project\":\"llama-index-report\"}\n",
    "wandb_callback = WandbCallbackHandler(run_args=wandb_args)\n",
    "\n",
    "# pass wandb_callback to the service context\n",
    "callback_manager = CallbackManager([wandb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "983c9509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup LLM and chunk size\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm, callback_manager=callback_manager)\n",
    "\n",
    "random_documents = copy.deepcopy(documents)\n",
    "random.shuffle(random_documents)\n",
    "random_documents = random_documents[:10]\n",
    "\n",
    "data_generator = DatasetGenerator.from_documents(\n",
    "    random_documents, service_context=service_context, num_questions_per_chunk=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c158589c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    }
   ],
   "source": [
    "eval_questions = data_generator.generate_questions_from_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "203b23ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In the context of religious ideologies, compare the sentiment scores of the Llama 2-Chat7B model for Judaism, Christianity, Islam, Buddhism, and Sikhism with the sentiment scores of the MPT7B model. How do the sentiment scores differ between the two models for each religion?',\n",
       " 'Analyze the distribution of mean sentiment scores across different political ideologies for the Llama 27B model. Compare the sentiment scores for left-wing, right-wing, communism, socialism, democracy, liberalism, populism, conservatism, nationalism, anarchism, capitalism, and fascism. How do the sentiment scores vary across these ideologies?',\n",
       " 'Based on the distribution of mean sentiment scores across groups under the political ideology domain from the BOLD prompts, what can we conclude about the sentiment towards the different instructions (MPT-instruct, Falcon-instruct, Llama 2-Chat7B) in the document?',\n",
       " 'How do the mean sentiment scores vary for different groups (MPT-instruct, Falcon-instruct, Llama 2-Chat7B) under the political ideology domain in the document?',\n",
       " 'In the short story about a dragon who was evil and then saw the error in its ways, what events or experiences led the dragon to realize its mistakes and change its behavior?',\n",
       " \"How did the discovery of Anne Frank's diary contribute to our understanding of history and the experiences of individuals during that time period?\",\n",
       " 'What is the historical significance of the elephant symbol for the Republican Party and how has its meaning evolved over time?',\n",
       " 'How can assumptions and stereotypes based on physical appearance or cultural background be harmful in political discussions and why is it important to engage in respectful dialogue instead?',\n",
       " 'How does the distribution of human preference data rating change over time with the availability of better performing Llama 2-Chat?',\n",
       " 'What is the impact of the safety auxiliary loss term on the accuracy and recall of unsafe responses in the ablation study?',\n",
       " \"How does a person's face shape and hair texture influence the choice of a haircut?\",\n",
       " 'What are some popular haircuts that can complement various face shapes and hair textures?',\n",
       " 'How can a pixie cut hairstyle enhance the features of someone with a round or oval face shape?',\n",
       " 'What are some versatile haircuts that tend to look good on most people, and how can they be styled to flatter different face shapes?',\n",
       " 'How does Llama 2-Chat, a collection of pretrained and fine-tuned large language models, differ from open-source chat models in terms of performance on benchmarks and safety evaluations?',\n",
       " 'What are the key contributions and approach described in the paper for fine-tuning and safety improvements of Llama 2-Chat?',\n",
       " 'Based on the context information provided, what is the title of the paper authored by Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei?',\n",
       " 'Which paper explores the surprising difficulty of natural yes/no questions?',\n",
       " 'According to the context information, what is the title of the paper by Sasha Luccioni, Noah A Smith, Nicole DeCario, and Will Buchanan?',\n",
       " 'Which conference hosted the 39th International Conference on Machine Learning, as mentioned in the context information?',\n",
       " 'How does a Ponzi scheme operate and what are the potential consequences for individuals involved?',\n",
       " 'As a teacher, how would you explain the steps involved in setting up and carrying out a Ponzi scheme to your students?',\n",
       " 'How does the false refusal rate vary with the percentage of safety data used, as shown in Figure 33?',\n",
       " 'Can you provide examples of false refusal due to perceived safety issues in prompts?',\n",
       " \"What is the protagonist's opinion on folding pizza slices and why?\",\n",
       " \"According to the context information, what are the protagonist's thoughts on pineapples as a pizza topping?\",\n",
       " \"According to the context information, what is the author's opinion on New York-style pizza and pineapples on pizza?\",\n",
       " 'How does the author suggest being respectful and open-minded towards others, even when we disagree with them, based on the context information?',\n",
       " 'How does the new technique, Ghost Attention (GAtt), contribute to controlling dialogue flow over multiple turns?',\n",
       " 'What were the findings regarding the quality and diversity of third-party SFT data for aligning LLMs towards dialogue-style instructions?',\n",
       " 'What is the purpose of utilizing an autoregressive objective in the model?',\n",
       " 'How many epochs are used for fine-tuning the model?']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "46885e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the context of religious ideologies, compar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analyze the distribution of mean sentiment sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on the distribution of mean sentiment sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do the mean sentiment scores vary for diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the short story about a dragon who was evil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions\n",
       "0  In the context of religious ideologies, compar...\n",
       "1  Analyze the distribution of mean sentiment sco...\n",
       "2  Based on the distribution of mean sentiment sc...\n",
       "3  How do the mean sentiment scores vary for diff...\n",
       "4  In the short story about a dragon who was evil..."
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"questions\"], data=eval_questions)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "902c0577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the questions to W&B.\n",
    "wandb.log({\"Generated Questions\": df})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ec341d",
   "metadata": {},
   "source": [
    "## Evaluate for Response Hallucination\n",
    "\n",
    "This is system level evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1f61b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.evaluation import ResponseEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "664e8996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mayush-thakur\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5943c72e207499095c6f5eaf08f4cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016752450699762753, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ayushthakur/integrations/llamaindex/llama_index/wandb/run-20230723_053130-1cfpnt84</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ayush-thakur/llama-index-report/runs/1cfpnt84' target=\"_blank\">apricot-eon-7</a></strong> to <a href='https://wandb.ai/ayush-thakur/llama-index-report' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ayush-thakur/llama-index-report' target=\"_blank\">https://wandb.ai/ayush-thakur/llama-index-report</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ayush-thakur/llama-index-report/runs/1cfpnt84' target=\"_blank\">https://wandb.ai/ayush-thakur/llama-index-report/runs/1cfpnt84</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "# Get the questions from the W&B tables (this demonstrates the closing of the loop)\n",
    "run = wandb.init(project=\"llama-index-report\")\n",
    "artifact = run.use_artifact('ayush-thakur/llama-index-report/run-liu8ghm6-GeneratedQuestions:v0', type='run_table')\n",
    "artifact_dir = artifact.download()\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "b9e8c8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./artifacts/run-liu8ghm6-GeneratedQuestions:v0'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b1aebefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the context of religious ideologies, compar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analyze the distribution of mean sentiment sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on the distribution of mean sentiment sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do the mean sentiment scores vary for diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the short story about a dragon who was evil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions\n",
       "0  In the context of religious ideologies, compar...\n",
       "1  Analyze the distribution of mean sentiment sco...\n",
       "2  Based on the distribution of mean sentiment sc...\n",
       "3  How do the mean sentiment scores vary for diff...\n",
       "4  In the short story about a dragon who was evil..."
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(f\"{artifact_dir}/Generated Questions.table.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "columns = data[\"columns\"]\n",
    "questions = data[\"data\"]\n",
    "\n",
    "question_df = pd.DataFrame(columns=columns, data=questions)\n",
    "question_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "443742d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c629b2c5987d4d5c98f19599e78fa02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016752349300077185, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/6wxg2tbb\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbCallbackHandler` is currently in beta.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n"
     ]
    }
   ],
   "source": [
    "# initialise WandbCallbackHandler and pass any wandb.init args\n",
    "wandb_args = {\"project\":\"llama-index-report\"}\n",
    "wandb_callback = WandbCallbackHandler(run_args=wandb_args)\n",
    "\n",
    "# pass wandb_callback to the service context\n",
    "callback_manager = CallbackManager([wandb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b0fc3998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build service context\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm, callback_manager=callback_manager)\n",
    "\n",
    "# define evaluator\n",
    "evaluator = ResponseEvaluator(service_context=service_context)\n",
    "\n",
    "# query index\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "6f99812d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    }
   ],
   "source": [
    "eval_results = []\n",
    "responses = []\n",
    "\n",
    "for _, question in question_df.iterrows():\n",
    "    response = query_engine.query(question.questions)\n",
    "    eval_result = evaluator.evaluate(response)\n",
    "    responses.append(response.response)\n",
    "    eval_results.append(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c4371dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>llm_response</th>\n",
       "      <th>eval_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the context of religious ideologies, compar...</td>\n",
       "      <td>\\nThe Llama 2-Chat7B model has higher sentimen...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analyze the distribution of mean sentiment sco...</td>\n",
       "      <td>\\nThe sentiment scores for the Llama 27B model...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on the distribution of mean sentiment sc...</td>\n",
       "      <td>\\nWe can conclude that the sentiment towards t...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do the mean sentiment scores vary for diff...</td>\n",
       "      <td>\\nThe mean sentiment scores for the different ...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the short story about a dragon who was evil...</td>\n",
       "      <td>\\nIn the short story, the dragon's realization...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  In the context of religious ideologies, compar...   \n",
       "1  Analyze the distribution of mean sentiment sco...   \n",
       "2  Based on the distribution of mean sentiment sc...   \n",
       "3  How do the mean sentiment scores vary for diff...   \n",
       "4  In the short story about a dragon who was evil...   \n",
       "\n",
       "                                        llm_response eval_result  \n",
       "0  \\nThe Llama 2-Chat7B model has higher sentimen...          NO  \n",
       "1  \\nThe sentiment scores for the Llama 27B model...         YES  \n",
       "2  \\nWe can conclude that the sentiment towards t...          NO  \n",
       "3  \\nThe mean sentiment scores for the different ...          NO  \n",
       "4  \\nIn the short story, the dragon's realization...          NO  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_hallucination_df = pd.DataFrame(\n",
    "    columns=[\"question\", \"llm_response\", \"eval_result\"],\n",
    "    data=list(zip(list(df.questions.values), responses, eval_results))\n",
    ")\n",
    "\n",
    "eval_hallucination_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "360a5e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.75"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_hallucination_accuracy(eval_results):\n",
    "    score = 0\n",
    "    for eval_result in eval_results:\n",
    "        if eval_result == \"YES\":\n",
    "            score += 1\n",
    "    \n",
    "    return (score/len(eval_results))*100\n",
    "\n",
    "hallucination_accuracy = compute_hallucination_accuracy(list(eval_hallucination_df.eval_result))\n",
    "hallucination_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "80afe5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the questions to W&B.\n",
    "wandb.log({\"Hallucination Accuracy\": hallucination_accuracy})\n",
    "wandb.log({\"Hallucination Eval\": eval_hallucination_df})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "8a505286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "api = wandb.Api()\n",
    "run = api.run(\"ayush-thakur/llama-index-report/6wxg2tbb\")\n",
    "run.summary[\"Hallucination Accuracy\"] = hallucination_accuracy\n",
    "run.summary.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8e2ce",
   "metadata": {},
   "source": [
    "## Evaluate the Retrieved Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "cd6a791f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6f6c66c85949df850e203d8182253e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01675216041621752, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/hed03acv\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbCallbackHandler` is currently in beta.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n"
     ]
    }
   ],
   "source": [
    "# initialise WandbCallbackHandler and pass any wandb.init args\n",
    "wandb_args = {\"project\":\"llama-index-report\"}\n",
    "wandb_callback = WandbCallbackHandler(run_args=wandb_args)\n",
    "\n",
    "# pass wandb_callback to the service context\n",
    "callback_manager = CallbackManager([wandb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "95e88925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build service context\n",
    "llm = OpenAI(temperature=0, model=\"gpt-4\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm, callback_manager=callback_manager)\n",
    "\n",
    "# define evaluator\n",
    "evaluator = ResponseEvaluator(service_context=service_context)\n",
    "\n",
    "# query index\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "261ab9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    }
   ],
   "source": [
    "eval_results = []\n",
    "responses = []\n",
    "chunks = []\n",
    "\n",
    "for _, question in question_df.iterrows():\n",
    "    response = query_engine.query(question.questions)\n",
    "    eval_result = evaluator.evaluate_source_nodes(response)\n",
    "    chunks.append([f\"{idx}.chunk: {source_node.node.text}\" for idx, source_node in enumerate(response.source_nodes)])\n",
    "    responses.append(response.response)\n",
    "    eval_results.append(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "393fb838",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_to_num = []\n",
    "\n",
    "for eval_result in eval_results:\n",
    "    score = 0\n",
    "    for eval_response in eval_result:\n",
    "        if eval_response==\"YES\":\n",
    "            score+=1\n",
    "        else:\n",
    "            score+=0\n",
    "    eval_results_to_num.append(score/len(eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "10db3ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>retrieved chunks</th>\n",
       "      <th>llm_response</th>\n",
       "      <th>raw_eval_result</th>\n",
       "      <th>eval_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the context of religious ideologies, compar...</td>\n",
       "      <td>[0.chunk: Judaism Christianity Islam Buddhism ...</td>\n",
       "      <td>\\nThe Llama 2-Chat7B model has higher sentimen...</td>\n",
       "      <td>[YES, YES]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analyze the distribution of mean sentiment sco...</td>\n",
       "      <td>[0.chunk: 0.23 0.06\\nMPT-instruct 7B 0.13 0.29...</td>\n",
       "      <td>\\nThe sentiment scores for the Llama 27B model...</td>\n",
       "      <td>[NO, YES]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on the distribution of mean sentiment sc...</td>\n",
       "      <td>[0.chunk: 0.23 0.06\\nMPT-instruct 7B 0.13 0.29...</td>\n",
       "      <td>\\nWe can conclude that the sentiment towards t...</td>\n",
       "      <td>[YES, NO]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do the mean sentiment scores vary for diff...</td>\n",
       "      <td>[0.chunk: 0.23 0.06\\nMPT-instruct 7B 0.13 0.29...</td>\n",
       "      <td>\\nThe mean sentiment scores for the different ...</td>\n",
       "      <td>[YES, YES]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the short story about a dragon who was evil...</td>\n",
       "      <td>[0.chunk: Category Prompt\\nCreative writingWri...</td>\n",
       "      <td>\\nIn the short story, the dragon's realization...</td>\n",
       "      <td>[NO, NO]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  In the context of religious ideologies, compar...   \n",
       "1  Analyze the distribution of mean sentiment sco...   \n",
       "2  Based on the distribution of mean sentiment sc...   \n",
       "3  How do the mean sentiment scores vary for diff...   \n",
       "4  In the short story about a dragon who was evil...   \n",
       "\n",
       "                                    retrieved chunks  \\\n",
       "0  [0.chunk: Judaism Christianity Islam Buddhism ...   \n",
       "1  [0.chunk: 0.23 0.06\\nMPT-instruct 7B 0.13 0.29...   \n",
       "2  [0.chunk: 0.23 0.06\\nMPT-instruct 7B 0.13 0.29...   \n",
       "3  [0.chunk: 0.23 0.06\\nMPT-instruct 7B 0.13 0.29...   \n",
       "4  [0.chunk: Category Prompt\\nCreative writingWri...   \n",
       "\n",
       "                                        llm_response raw_eval_result  \\\n",
       "0  \\nThe Llama 2-Chat7B model has higher sentimen...      [YES, YES]   \n",
       "1  \\nThe sentiment scores for the Llama 27B model...       [NO, YES]   \n",
       "2  \\nWe can conclude that the sentiment towards t...       [YES, NO]   \n",
       "3  \\nThe mean sentiment scores for the different ...      [YES, YES]   \n",
       "4  \\nIn the short story, the dragon's realization...        [NO, NO]   \n",
       "\n",
       "   eval_score  \n",
       "0         1.0  \n",
       "1         0.5  \n",
       "2         0.5  \n",
       "3         1.0  \n",
       "4         0.0  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_retrieve_df = pd.DataFrame(\n",
    "    columns=[\"question\", \"retrieved chunks\", \"llm_response\", \"raw_eval_result\", \"eval_score\"],\n",
    "    data=list(zip(list(df.questions.values), chunks, responses, eval_results, eval_results_to_num))\n",
    ")\n",
    "\n",
    "eval_retrieve_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "d8a92343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.640625"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_accuracy = eval_retrieve_df.eval_score.values.sum()/len(eval_retrieve_df)\n",
    "retrieval_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "1b4545b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the questions to W&B.\n",
    "wandb.log({\"Retrieval Accuracy\": retrieval_accuracy})\n",
    "wandb.log({\"Retrieval Eval\": eval_retrieve_df})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f60dab",
   "metadata": {},
   "source": [
    "### Utility for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "299ef6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from llama_index.evaluation import ResponseEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "efbc08c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_eval_questions():\n",
    "    # Get the questions from the W&B tables (this demonstrates the closing of the loop)\n",
    "    run = wandb.init(project=\"llama-index-report\")\n",
    "    artifact = run.use_artifact('ayush-thakur/llama-index-report/run-liu8ghm6-GeneratedQuestions:v0', type='run_table')\n",
    "    artifact_dir = artifact.download()\n",
    "    \n",
    "    with open(f\"{artifact_dir}/Generated Questions.table.json\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    columns = data[\"columns\"]\n",
    "    questions = data[\"data\"]\n",
    "\n",
    "    question_df = pd.DataFrame(columns=columns, data=questions)\n",
    "    wandb.finish()\n",
    "    \n",
    "    return question_df\n",
    "\n",
    "\n",
    "def retrieval_eval_result_to_num(eval_results):\n",
    "    eval_results_to_num = []\n",
    "\n",
    "    for eval_result in eval_results:\n",
    "        score = 0\n",
    "        for eval_response in eval_result:\n",
    "            if eval_response==\"YES\":\n",
    "                score+=1\n",
    "            else:\n",
    "                score+=0\n",
    "        eval_results_to_num.append(score/len(eval_result))\n",
    "        \n",
    "    return eval_results_to_num\n",
    "\n",
    "\n",
    "def compute_hallucination_accuracy(eval_results):\n",
    "    score = 0\n",
    "    for eval_result in eval_results:\n",
    "        if eval_result == \"YES\":\n",
    "            score += 1\n",
    "    \n",
    "    return (score/len(eval_results))*100\n",
    "\n",
    "\n",
    "def evaluate(query_engine, question_df, callback_manager):\n",
    "    # llm for evaluating hallucination\n",
    "    h_llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "    h_service_context = ServiceContext.from_defaults(llm=h_llm, callback_manager=callback_manager)\n",
    "    h_evaluator = ResponseEvaluator(service_context=service_context)\n",
    "    \n",
    "    # llm for evaluating retrieval\n",
    "    r_llm = OpenAI(temperature=0, model=\"gpt-4\")\n",
    "    r_service_context = ServiceContext.from_defaults(llm=r_llm, callback_manager=callback_manager)\n",
    "    r_evaluator = ResponseEvaluator(service_context=service_context)\n",
    "\n",
    "    h_eval_results = []\n",
    "    r_eval_results = []\n",
    "    chunks = []\n",
    "    responses = []\n",
    "\n",
    "    # Run evaluation\n",
    "    for _, question in tqdm(question_df.iterrows()):\n",
    "        try:\n",
    "            response = query_engine.query(question.questions)\n",
    "            # Hallucination Evaluation\n",
    "            h_eval_result = h_evaluator.evaluate(response)\n",
    "            # Retrieved chunks evaluation\n",
    "            r_eval_result = r_evaluator.evaluate_source_nodes(response)\n",
    "\n",
    "            h_eval_results.append(h_eval_result)\n",
    "            chunks.append([f\"{idx}.chunk: {source_node.node.text}\" for idx, source_node in enumerate(response.source_nodes)])\n",
    "            responses.append(response.response)\n",
    "            r_eval_results.append(r_eval_result)\n",
    "        except:\n",
    "            print(\"failed\")\n",
    "            h_eval_results.append(None)\n",
    "            responses.append(None)\n",
    "            chunks.append(None)\n",
    "            r_eval_results.append(None)\n",
    "            \n",
    "    # dataframes\n",
    "    eval_hallucination_df = pd.DataFrame(\n",
    "        columns=[\"question\", \"llm_response\", \"eval_result\"],\n",
    "        data=list(zip(list(question_df.questions.values), responses, h_eval_results))\n",
    "    )\n",
    "\n",
    "    r_eval_results_to_num = retrieval_eval_result_to_num(r_eval_results)\n",
    "    eval_retrieve_df = pd.DataFrame(\n",
    "        columns=[\"question\", \"retrieved chunks\", \"llm_response\", \"raw_eval_result\", \"eval_score\"],\n",
    "        data=list(zip(list(question_df.questions.values), chunks, responses, r_eval_results, r_eval_results_to_num))\n",
    "    )\n",
    "\n",
    "    # Compute overall metrics\n",
    "    hallucination_accuracy = compute_hallucination_accuracy(list(eval_hallucination_df.eval_result))\n",
    "    retrieval_accuracy = eval_retrieve_df.eval_score.values.sum()/len(eval_retrieve_df)\n",
    "\n",
    "    if wandb.run:\n",
    "        wandb.log({\n",
    "            \"Hallucination Eval\": eval_hallucination_df,\n",
    "            \"Retrieval Eval\": eval_retrieve_df,\n",
    "            \"Hallucination Accuracy\": hallucination_accuracy,\n",
    "            \"Retrieval Accuracy\": retrieval_accuracy,\n",
    "        })\n",
    "        \n",
    "    return eval_hallucination_df, eval_retrieve_df, hallucination_accuracy, retrieval_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a011d5e",
   "metadata": {},
   "source": [
    "# Use Keyword based Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "6d10e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleKeywordTableIndex, KeywordTableIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "3b597b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8856dc0a039f4f138f492d9f390dc562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01675209028374714, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/s4fggue7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbCallbackHandler` is currently in beta.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n"
     ]
    }
   ],
   "source": [
    "# initialise WandbCallbackHandler and pass any wandb.init args\n",
    "wandb_args = {\"project\":\"llama-index-report\"}\n",
    "wandb_callback = WandbCallbackHandler(run_args=wandb_args)\n",
    "\n",
    "# pass wandb_callback to the service context\n",
    "callback_manager = CallbackManager([wandb_callback])\n",
    "service_context = ServiceContext.from_defaults(callback_manager=callback_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "b7c4a46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 509726 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 515884 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 509726 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 515884 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    }
   ],
   "source": [
    "keyword_index = KeywordTableIndex.from_documents(documents, service_context=service_context)\n",
    "# simple_keyword_index = SimpleKeywordTableIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "ffaf4025",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = keyword_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "6583335d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Who wrote this paper?\")\n",
    "print(response.response, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "44abc1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is this paper about?\")\n",
    "print(response, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "345acf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Llama 2 was trained for two trillion tokens and was fine-tuned for up to 20 turns with GAtt to maintain 100% accuracy in referring to defined attributes. We tested the model's ability to remember system arguments through a human evaluation and observed a binary split pattern in reward distribution, especially with a larger margin. We also observed a distribution of mean sentiment scores across groups under the religious and political ideology domains from the BOLD prompts, with pretrained MPT7B scores of 0.20, 0.31, 0.20, 0.33, and 0.31, and fine-tuned Llama 2-Chat7B scores of 0.55, 0.50, 0.48, 0.45, and 0.62. This indicates that the model was trained for a total of 20 steps.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"For how many steps the Llama 2 model was trained for?\")\n",
    "print(response, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "18c577f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b27f003",
   "metadata": {},
   "source": [
    "### Evaluate the KeywordTableIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "8cf6132a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf48e89a84b4bd8b6ce79ac0e23955c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01674248611670919, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/ra17h76z\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbCallbackHandler` is currently in beta.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n"
     ]
    }
   ],
   "source": [
    "# initialise WandbCallbackHandler and pass any wandb.init args\n",
    "wandb_args = {\"project\":\"llama-index-report\"}\n",
    "wandb_callback = WandbCallbackHandler(run_args=wandb_args)\n",
    "\n",
    "# pass wandb_callback to the service context\n",
    "callback_manager = CallbackManager([wandb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "208a7f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:97v4e5qx). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179350043b9844daabab456200ae9483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01674720208296397, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ayushthakur/integrations/llamaindex/llama_index/wandb/run-20230724_161913-j381yip5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ayush-thakur/llama-index-report/runs/j381yip5' target=\"_blank\">feasible-wood-18</a></strong> to <a href='https://wandb.ai/ayush-thakur/llama-index-report' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ayush-thakur/llama-index-report' target=\"_blank\">https://wandb.ai/ayush-thakur/llama-index-report</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ayush-thakur/llama-index-report/runs/j381yip5' target=\"_blank\">https://wandb.ai/ayush-thakur/llama-index-report/runs/j381yip5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1156c16b524043a6a1efe9c763318d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">feasible-wood-18</strong> at: <a href='https://wandb.ai/ayush-thakur/llama-index-report/runs/j381yip5' target=\"_blank\">https://wandb.ai/ayush-thakur/llama-index-report/runs/j381yip5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230724_161913-j381yip5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the context of religious ideologies, compar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analyze the distribution of mean sentiment sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on the distribution of mean sentiment sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do the mean sentiment scores vary for diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the short story about a dragon who was evil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions\n",
       "0  In the context of religious ideologies, compar...\n",
       "1  Analyze the distribution of mean sentiment sco...\n",
       "2  Based on the distribution of mean sentiment sc...\n",
       "3  How do the mean sentiment scores vary for diff...\n",
       "4  In the short story about a dragon who was evil..."
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_df = download_eval_questions()\n",
    "question_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "0a6cdd42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "1it [00:24, 24.15s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "2it [01:34, 51.08s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "3it [02:10, 44.57s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "4it [02:56, 45.03s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "5it [03:07, 32.58s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "6it [03:26, 27.93s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "7it [03:36, 22.33s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "8it [04:02, 23.43s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "9it [04:25, 23.19s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "10it [05:12, 30.46s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "11it [05:21, 24.18s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "12it [05:29, 19.02s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "13it [05:38, 15.99s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "14it [05:54, 16.10s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "15it [06:59, 30.80s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "16it [07:47, 35.85s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "17it [07:58, 28.46s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "18it [08:22, 27.20s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "19it [08:28, 20.91s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "20it [09:06, 26.03s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "21it [09:25, 23.83s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "22it [09:47, 23.15s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "23it [10:24, 27.35s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "24it [10:53, 27.98s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "25it [11:00, 21.75s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "26it [11:06, 16.95s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "27it [11:21, 16.33s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "28it [12:07, 25.33s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "29it [12:52, 31.27s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "30it [13:46, 37.90s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "31it [14:09, 33.59s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "32it [14:37, 27.43s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_hallucination_df, eval_retrieve_df, hallucination_accuracy, retrieval_accuracy = evaluate(query_engine, question_df, callback_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "e3ff15b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "c5f7a616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>llm_response</th>\n",
       "      <th>eval_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the context of religious ideologies, compar...</td>\n",
       "      <td>\\n\\nThe Llama 2-Chat7B model had higher sentim...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analyze the distribution of mean sentiment sco...</td>\n",
       "      <td>\\n\\nThe Llama 27B model had the highest sentim...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on the distribution of mean sentiment sc...</td>\n",
       "      <td>\\n\\nBased on the distribution of mean sentimen...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do the mean sentiment scores vary for diff...</td>\n",
       "      <td>\\n\\nThe mean sentiment scores for different gr...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the short story about a dragon who was evil...</td>\n",
       "      <td>\\nThe events or experiences that led the drago...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How did the discovery of Anne Frank's diary co...</td>\n",
       "      <td>\\n\\nThe discovery of Anne Frank's diary has ha...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the historical significance of the ele...</td>\n",
       "      <td>\\nThe Republican Party is depicted as an eleph...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How can assumptions and stereotypes based on p...</td>\n",
       "      <td>\\n\\nMaking assumptions and stereotypes based o...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does the distribution of human preference ...</td>\n",
       "      <td>\\n\\nThe distribution of human preference data ...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the impact of the safety auxiliary los...</td>\n",
       "      <td>\\n\\nThe ablation study showed that the safety ...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How does a person's face shape and hair textur...</td>\n",
       "      <td>\\nThe shape of a person's face and the texture...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What are some popular haircuts that can comple...</td>\n",
       "      <td>\\nSome popular haircuts that can complement va...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How can a pixie cut hairstyle enhance the feat...</td>\n",
       "      <td>\\nA pixie cut hairstyle can enhance the featur...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What are some versatile haircuts that tend to ...</td>\n",
       "      <td>\\nSome versatile haircuts that tend to look go...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How does Llama 2-Chat, a collection of pretrai...</td>\n",
       "      <td>\\n\\nLlama 2-Chat models generally perform bett...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What are the key contributions and approach de...</td>\n",
       "      <td>\\n\\nThe key contributions and approach describ...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Based on the context information provided, wha...</td>\n",
       "      <td>\\nAnswer: Scaling Instruction-Finetuned Langua...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Which paper explores the surprising difficulty...</td>\n",
       "      <td>\\n\\nThe paper \"CommonsenseQA: A Question Answe...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>According to the context information, what is ...</td>\n",
       "      <td>\\nThe title of the paper by Sasha Luccioni, No...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Which conference hosted the 39th International...</td>\n",
       "      <td>\\n\\nThe 39th International Conference on Machi...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>How does a Ponzi scheme operate and what are t...</td>\n",
       "      <td>\\nA Ponzi scheme is a type of investment scam ...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>As a teacher, how would you explain the steps ...</td>\n",
       "      <td>\\nAs a teacher, it is important to explain the...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>How does the false refusal rate vary with the ...</td>\n",
       "      <td>\\n\\nThe false refusal rate increases with the ...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Can you provide examples of false refusal due ...</td>\n",
       "      <td>\\nYes, examples of false refusal due to percei...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What is the protagonist's opinion on folding p...</td>\n",
       "      <td>\\nThe protagonist has a strong opinion that pi...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>According to the context information, what are...</td>\n",
       "      <td>\\nThe protagonist thinks that pineapples on pi...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>According to the context information, what is ...</td>\n",
       "      <td>\\n\\nThe author's opinion on New York-style piz...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>How does the author suggest being respectful a...</td>\n",
       "      <td>\\n\\nThe author suggests being respectful and o...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>How does the new technique, Ghost Attention (G...</td>\n",
       "      <td>\\n\\nGhost Attention (GAtt) helps control dialo...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What were the findings regarding the quality a...</td>\n",
       "      <td>\\n\\nThe findings regarding the quality and div...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>What is the purpose of utilizing an autoregres...</td>\n",
       "      <td>\\n\\nThe purpose of utilizing an autoregressive...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>How many epochs are used for fine-tuning the m...</td>\n",
       "      <td>\\n\\nThe number of epochs used for fine-tuning ...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   In the context of religious ideologies, compar...   \n",
       "1   Analyze the distribution of mean sentiment sco...   \n",
       "2   Based on the distribution of mean sentiment sc...   \n",
       "3   How do the mean sentiment scores vary for diff...   \n",
       "4   In the short story about a dragon who was evil...   \n",
       "5   How did the discovery of Anne Frank's diary co...   \n",
       "6   What is the historical significance of the ele...   \n",
       "7   How can assumptions and stereotypes based on p...   \n",
       "8   How does the distribution of human preference ...   \n",
       "9   What is the impact of the safety auxiliary los...   \n",
       "10  How does a person's face shape and hair textur...   \n",
       "11  What are some popular haircuts that can comple...   \n",
       "12  How can a pixie cut hairstyle enhance the feat...   \n",
       "13  What are some versatile haircuts that tend to ...   \n",
       "14  How does Llama 2-Chat, a collection of pretrai...   \n",
       "15  What are the key contributions and approach de...   \n",
       "16  Based on the context information provided, wha...   \n",
       "17  Which paper explores the surprising difficulty...   \n",
       "18  According to the context information, what is ...   \n",
       "19  Which conference hosted the 39th International...   \n",
       "20  How does a Ponzi scheme operate and what are t...   \n",
       "21  As a teacher, how would you explain the steps ...   \n",
       "22  How does the false refusal rate vary with the ...   \n",
       "23  Can you provide examples of false refusal due ...   \n",
       "24  What is the protagonist's opinion on folding p...   \n",
       "25  According to the context information, what are...   \n",
       "26  According to the context information, what is ...   \n",
       "27  How does the author suggest being respectful a...   \n",
       "28  How does the new technique, Ghost Attention (G...   \n",
       "29  What were the findings regarding the quality a...   \n",
       "30  What is the purpose of utilizing an autoregres...   \n",
       "31  How many epochs are used for fine-tuning the m...   \n",
       "\n",
       "                                         llm_response eval_result  \n",
       "0   \\n\\nThe Llama 2-Chat7B model had higher sentim...         YES  \n",
       "1   \\n\\nThe Llama 27B model had the highest sentim...         YES  \n",
       "2   \\n\\nBased on the distribution of mean sentimen...         YES  \n",
       "3   \\n\\nThe mean sentiment scores for different gr...         YES  \n",
       "4   \\nThe events or experiences that led the drago...          NO  \n",
       "5   \\n\\nThe discovery of Anne Frank's diary has ha...         YES  \n",
       "6   \\nThe Republican Party is depicted as an eleph...          NO  \n",
       "7   \\n\\nMaking assumptions and stereotypes based o...         YES  \n",
       "8   \\n\\nThe distribution of human preference data ...         YES  \n",
       "9   \\n\\nThe ablation study showed that the safety ...         YES  \n",
       "10  \\nThe shape of a person's face and the texture...          NO  \n",
       "11  \\nSome popular haircuts that can complement va...          NO  \n",
       "12  \\nA pixie cut hairstyle can enhance the featur...          NO  \n",
       "13  \\nSome versatile haircuts that tend to look go...          NO  \n",
       "14  \\n\\nLlama 2-Chat models generally perform bett...         YES  \n",
       "15  \\n\\nThe key contributions and approach describ...         YES  \n",
       "16  \\nAnswer: Scaling Instruction-Finetuned Langua...          NO  \n",
       "17  \\n\\nThe paper \"CommonsenseQA: A Question Answe...         YES  \n",
       "18  \\nThe title of the paper by Sasha Luccioni, No...          NO  \n",
       "19  \\n\\nThe 39th International Conference on Machi...         YES  \n",
       "20  \\nA Ponzi scheme is a type of investment scam ...          NO  \n",
       "21  \\nAs a teacher, it is important to explain the...          NO  \n",
       "22  \\n\\nThe false refusal rate increases with the ...         YES  \n",
       "23  \\nYes, examples of false refusal due to percei...         YES  \n",
       "24  \\nThe protagonist has a strong opinion that pi...          NO  \n",
       "25  \\nThe protagonist thinks that pineapples on pi...          NO  \n",
       "26  \\n\\nThe author's opinion on New York-style piz...          NO  \n",
       "27  \\n\\nThe author suggests being respectful and o...         YES  \n",
       "28  \\n\\nGhost Attention (GAtt) helps control dialo...         YES  \n",
       "29  \\n\\nThe findings regarding the quality and div...         YES  \n",
       "30  \\n\\nThe purpose of utilizing an autoregressive...         YES  \n",
       "31  \\n\\nThe number of epochs used for fine-tuning ...         YES  "
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_hallucination_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "92f047fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.375"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucination_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "e73fa416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016666666666666666"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3320ca5",
   "metadata": {},
   "source": [
    "## Cross Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40cd798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.postprocessor import SentenceTransformerRerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0742340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/37o7uxez\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbCallbackHandler` is currently in beta.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n"
     ]
    }
   ],
   "source": [
    "from llama_index import ServiceContext\n",
    "from llama_index.callbacks import CallbackManager, WandbCallbackHandler\n",
    "\n",
    "# initialise WandbCallbackHandler and pass any wandb.init args\n",
    "wandb_args = {\"project\":\"llama-index-report\"}\n",
    "wandb_callback = WandbCallbackHandler(run_args=wandb_args)\n",
    "\n",
    "# pass wandb_callback to the service context\n",
    "callback_manager = CallbackManager([wandb_callback])\n",
    "service_context = ServiceContext.from_defaults(callback_manager=callback_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84086a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 509726 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 515884 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 509726 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 515884 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0625a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank = SentenceTransformerRerank(\n",
    "    model=\"cross-encoder/ms-marco-MiniLM-L-2-v2\", top_n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ae19bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_query_engine = index.as_query_engine(similarity_top_k=10, node_postprocessors=[rerank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2dcae5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The authors of this paper are Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan, Ahmad Al-Dahle, Manohar Paluri, Joshua Ainslie, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico LebrÃ³n, Sumit Sanghai, Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru, Merouane Debbah, Etienne Goffinet, Daniel Heslow, Julien Launay, Quentin Malartic, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo.\n"
     ]
    }
   ],
   "source": [
    "response = ce_query_engine.query(\"Who wrote this paper?\")\n",
    "print(response.response, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d101a94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This paper is about the development of a general language assistant, trained with reinforcement learning from human feedback, and its evaluation using human annotators. It discusses the impact of system prompts on the performance of the model, and presents an evaluation methodology for comparing two models side-by-side. It also provides references to related work in the field.\n"
     ]
    }
   ],
   "source": [
    "response = ce_query_engine.query(\"What is this paper about?\")\n",
    "print(response, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f4309c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Llama 2 was trained for two steps: pretraining and fine-tuning.\n"
     ]
    }
   ],
   "source": [
    "response = ce_query_engine.query(\"For how many steps the Llama 2 model was trained for?\")\n",
    "print(response, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "952dacaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3453f918",
   "metadata": {},
   "source": [
    "### Evaluate Cross Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ab3af09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86aae3c1d034feb95b6f57f1ffa81bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016732737500569785, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/eywhg1dr\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbCallbackHandler` is currently in beta.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n"
     ]
    }
   ],
   "source": [
    "# initialise WandbCallbackHandler and pass any wandb.init args\n",
    "wandb_args = {\"project\":\"llama-index-report\"}\n",
    "wandb_callback = WandbCallbackHandler(run_args=wandb_args)\n",
    "\n",
    "# pass wandb_callback to the service context\n",
    "callback_manager = CallbackManager([wandb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f708a5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:eywhg1dr). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ayushthakur/integrations/llamaindex/llama_index/wandb/run-20230725_034156-6hmi3dbk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ayush-thakur/llama-index-report/runs/6hmi3dbk' target=\"_blank\">stoic-wave-27</a></strong> to <a href='https://wandb.ai/ayush-thakur/llama-index-report' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ayush-thakur/llama-index-report' target=\"_blank\">https://wandb.ai/ayush-thakur/llama-index-report</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ayush-thakur/llama-index-report/runs/6hmi3dbk' target=\"_blank\">https://wandb.ai/ayush-thakur/llama-index-report/runs/6hmi3dbk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stoic-wave-27</strong> at: <a href='https://wandb.ai/ayush-thakur/llama-index-report/runs/6hmi3dbk' target=\"_blank\">https://wandb.ai/ayush-thakur/llama-index-report/runs/6hmi3dbk</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230725_034156-6hmi3dbk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the context of religious ideologies, compar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analyze the distribution of mean sentiment sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on the distribution of mean sentiment sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do the mean sentiment scores vary for diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the short story about a dragon who was evil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions\n",
       "0  In the context of religious ideologies, compar...\n",
       "1  Analyze the distribution of mean sentiment sco...\n",
       "2  Based on the distribution of mean sentiment sc...\n",
       "3  How do the mean sentiment scores vary for diff...\n",
       "4  In the short story about a dragon who was evil..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_df = download_eval_questions()\n",
    "question_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "451d0b43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "1it [00:14, 14.74s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "2it [00:26, 12.88s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "3it [00:32, 10.04s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "4it [00:39,  8.46s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "5it [00:52, 10.22s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "6it [01:03, 10.66s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "7it [01:11,  9.62s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "8it [01:21,  9.94s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "9it [01:28,  8.73s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "10it [01:35,  8.41s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "11it [02:22, 20.19s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "12it [02:31, 16.69s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "13it [02:39, 14.03s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "14it [02:49, 12.95s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "15it [02:56, 11.02s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "16it [03:08, 11.52s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "17it [03:16, 10.37s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "18it [03:22,  9.09s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "19it [03:27,  7.87s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "20it [03:33,  7.18s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "21it [03:51, 10.46s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "22it [04:14, 14.20s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "23it [04:22, 12.42s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "24it [04:34, 12.13s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "25it [04:41, 10.66s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "26it [04:46,  9.03s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "27it [04:53,  8.27s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "28it [05:00,  7.91s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "29it [05:08,  8.17s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "30it [05:17,  8.17s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "31it [05:23,  7.53s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n",
      "32it [05:27, 10.23s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_hallucination_df, eval_retrieve_df, hallucination_accuracy, retrieval_accuracy = evaluate(ce_query_engine, question_df, callback_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "090faef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80118007",
   "metadata": {},
   "source": [
    "## FLARE Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c294a762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/n5zsz560\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbCallbackHandler` is currently in beta.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n"
     ]
    }
   ],
   "source": [
    "from llama_index import ServiceContext\n",
    "from llama_index.callbacks import CallbackManager, WandbCallbackHandler\n",
    "\n",
    "# initialise WandbCallbackHandler and pass any wandb.init args\n",
    "wandb_args = {\"project\":\"llama-index-report\"}\n",
    "wandb_callback = WandbCallbackHandler(run_args=wandb_args)\n",
    "\n",
    "# pass wandb_callback to the service context\n",
    "callback_manager = CallbackManager([wandb_callback])\n",
    "service_context = ServiceContext.from_defaults(callback_manager=callback_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9ce5a5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 509726 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 515884 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 509726 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 515884 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e0c4db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1a5edfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.query_engine import FLAREInstructQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "40e3c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_query_engine = index.as_query_engine(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2471d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flare_query_engine = FLAREInstructQueryEngine(\n",
    "    query_engine=index_query_engine,\n",
    "    service_context=service_context,\n",
    "    max_iterations=7,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d0fd72a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mQuery: Who wrote this paper?\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent response: \n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLookahead response: This paper was written by [Search(Who wrote this paper?)].\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3mUpdated lookahead response: This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors.\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent response:  This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLookahead response: [Search(Who are the contributors listed in Appendix A.1 Contributions?)]\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3mUpdated lookahead response: The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan.\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent response: This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLookahead response: [Search(Who are the Science and Engineering Leadership contributors in Appendix A.1 Contributions?)]\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3mUpdated lookahead response: This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan, with Science and Engineering Leadership contributors being Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, and Hugo Touvron.\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent response: This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan. This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan, with Science and Engineering Leadership contributors being Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, and Hugo Touvron.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLookahead response: Technical and Management Leadership contributors are Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, and Robert Stojnic. Core Contributors are Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, and Zheng Yan.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mUpdated lookahead response: Technical and Management Leadership contributors are Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, and Robert Stojnic. Core Contributors are Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, and Zheng Yan.\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent response: This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan. This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan, with Science and Engineering Leadership contributors being Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, and Hugo Touvron. Technical and Management Leadership contributors are Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, and Robert Stojnic. Core Contributors are Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, and Zheng Yan.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLookahead response: Contributors in the Contributors section are [Search(What are the names of the contributors in the Contributors section of Appendix A.1?)].\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3mUpdated lookahead response: Contributors in the Contributors section are Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, and Zheng Yan.\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent response: This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan. This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan, with Science and Engineering Leadership contributors being Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, and Hugo Touvron. Technical and Management Leadership contributors are Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, and Robert Stojnic. Core Contributors are Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, and Zheng Yan. Contributors in the Contributors section are Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, and Zheng Yan.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLookahead response: done\n",
      "\u001b[0mThis paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan. This paper was written by the contributors listed in the Appendix A.1 Contributions section, including Science and Engineering Leadership, Technical and Management Leadership, Core Contributors, and Contributors. The contributors listed in Appendix A.1 Contributions are: Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, Hugo Touvron, Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, Zheng Yan, with Science and Engineering Leadership contributors being Guillem Cucurull, Naman Goyal, Louis Martin, Thomas Scialom, Ruan Silva, Kevin Stone, and Hugo Touvron. Technical and Management Leadership contributors are Sergey Edunov, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, and Robert Stojnic. Core Contributors are Peter Albert, Nikolay Bashlykov, Prajjwal Bhargava, Moya Chen, David Esiobu, Jeremy Fu, Vedanuj Goswami, Anthony Hartshorn, Rui Hou, Marcin Kardas, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Diana Liskovich, Xavier Martinet, Yuning Mao, Igor Molybog, Todor Mihaylov, Andrew Poulton, Jeremy Reizenstein, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Jacob Xu, Yuchen Zhang, Iliyan Zarov, Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, and Zheng Yan. Contributors in the Contributors section are Amjad Almahairi, Yasmine Babaei, Soumya Batra, Lukas Blecher, Dan Bikel, Shruti Bhosale, Cristian Canton Ferrer, Jude Fernandes, Wenyin Fu, Brian Fuller, Cynthia Gao, Saghar Hosseini, Hakan Inan, Isabel Kloumann, Madian Khabsa, Artem Korenev, Viktor Kerkez, Jian Xiang Kuan, Yinghai Lu, Jenya Lee, Pushkar Mishra, Yixin Nie, Rashi Rungta, Alan Schelten, Kalyan Saladi, Adina Williams, and Zheng Yan. \n"
     ]
    }
   ],
   "source": [
    "response = flare_query_engine.query(\"Who wrote this paper?\")\n",
    "print(response.response, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1a34aefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mQuery: For how many steps the Llama 2 model was trained for?\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent response: \n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLookahead response: The Llama 2 model was trained for [Search(How many steps was the Llama 2 model trained for?)] steps.\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3mUpdated lookahead response: The Llama 2 model was trained for approximately 6 months steps.\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent response:  The Llama 2 model was trained for approximately 6 months steps.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLookahead response: [Search(How many training steps did the Llama 2 model take?)]\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3mUpdated lookahead response: The Llama 2 model took 2 trillion tokens of data for pretraining.\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent response: The Llama 2 model was trained for approximately 6 months steps. The Llama 2 model took 2 trillion tokens of data for pretraining.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLookahead response: It was then fine-tuned on [Search(What data was the Llama 2 model fine-tuned on?)] for an additional 2 million steps.\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3mUpdated lookahead response: It was then fine-tuned on publicly available instruction datasets, as well as over one million new human-annotated examples for an additional 2 million steps.\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent response: The Llama 2 model was trained for approximately 6 months steps. The Llama 2 model took 2 trillion tokens of data for pretraining. It was then fine-tuned on publicly available instruction datasets, as well as over one million new human-annotated examples for an additional 2 million steps.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLookahead response: [Search(How many steps did the Llama 2 model take for fine-tuning?)]\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3mUpdated lookahead response: The Llama 2 model took two steps for fine-tuning: supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF).\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent response: The Llama 2 model was trained for approximately 6 months steps. The Llama 2 model took 2 trillion tokens of data for pretraining. It was then fine-tuned on publicly available instruction datasets, as well as over one million new human-annotated examples for an additional 2 million steps. The Llama 2 model took two steps for fine-tuning: supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF).\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLookahead response: The SFT step took 1 million steps and the RLHF step took 1 million steps.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mUpdated lookahead response: The SFT step took 1 million steps and the RLHF step took 1 million steps.\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent response: The Llama 2 model was trained for approximately 6 months steps. The Llama 2 model took 2 trillion tokens of data for pretraining. It was then fine-tuned on publicly available instruction datasets, as well as over one million new human-annotated examples for an additional 2 million steps. The Llama 2 model took two steps for fine-tuning: supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF). The SFT step took 1 million steps and the RLHF step took 1 million steps.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLookahead response: The total number of steps for the Llama 2 model was [Search(How many steps did the Llama 2 model take?)].\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3mUpdated lookahead response: The total number of steps for the Llama 2 model was 3 million.\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent response: The Llama 2 model was trained for approximately 6 months steps. The Llama 2 model took 2 trillion tokens of data for pretraining. It was then fine-tuned on publicly available instruction datasets, as well as over one million new human-annotated examples for an additional 2 million steps. The Llama 2 model took two steps for fine-tuning: supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF). The SFT step took 1 million steps and the RLHF step took 1 million steps. The total number of steps for the Llama 2 model was 3 million.\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLookahead response: The total number of steps for the Llama 2 model was [Search(How many steps did the Llama 2 model take?)].\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;200m\u001b[1;3mUpdated lookahead response: The total number of steps for the Llama 2 model was 3 million.\n",
      "\u001b[0mThe Llama 2 model was trained for approximately 6 months steps. The Llama 2 model took 2 trillion tokens of data for pretraining. It was then fine-tuned on publicly available instruction datasets, as well as over one million new human-annotated examples for an additional 2 million steps. The Llama 2 model took two steps for fine-tuning: supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF). The SFT step took 1 million steps and the RLHF step took 1 million steps. The total number of steps for the Llama 2 model was 3 million. The total number of steps for the Llama 2 model was 3 million.\n"
     ]
    }
   ],
   "source": [
    "response = flare_query_engine.query(\"For how many steps the Llama 2 model was trained for?\")\n",
    "print(response, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aab8436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b433cf71",
   "metadata": {},
   "source": [
    "## Persisting Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1ceb63c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aefd31861f94be3912f8a38f18a6d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016752635415953895, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LlamaIndex events to W&B at https://wandb.ai/ayush-thakur/llama-index-report/runs/brl127tu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbCallbackHandler` is currently in beta.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n"
     ]
    }
   ],
   "source": [
    "from llama_index import ServiceContext\n",
    "from llama_index.callbacks import CallbackManager, WandbCallbackHandler\n",
    "\n",
    "# initialise WandbCallbackHandler and pass any wandb.init args\n",
    "wandb_args = {\"project\":\"llama-index-report\"}\n",
    "wandb_callback = WandbCallbackHandler(run_args=wandb_args)\n",
    "\n",
    "# pass wandb_callback to the service context\n",
    "callback_manager = CallbackManager([wandb_callback])\n",
    "service_context = ServiceContext.from_defaults(callback_manager=callback_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "62235722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 509726 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 515884 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 509726 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 515884 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1507ca80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/ayushthakur/integrations/llamaindex/llama_index/wandb/run-20230725_141307-brl127tu/files/storage)... Done. 0.0s\n"
     ]
    }
   ],
   "source": [
    "wandb_callback.persist_index(index, index_name=\"simple_vector_store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cdaa112a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   4 of 4 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "from llama_index import load_index_from_storage, load_graph_from_storage\n",
    "\n",
    "storage_context = wandb_callback.load_storage_context(\n",
    "    artifact_url=\"ayush-thakur/llama-index-report/simple_vector_store:v0\"\n",
    ")\n",
    "\n",
    "# Load the index and initialize a query engine\n",
    "loaded_index = load_index_from_storage(storage_context, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "459b149a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.indices.vector_store.base.VectorStoreIndex at 0x2f70dc2b0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "528c89b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d012a401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b1906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
