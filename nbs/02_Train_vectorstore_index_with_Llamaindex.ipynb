{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Install and import dependencies\n",
    "# !pip install llama-index transformers accelerate sentence_transformers\n",
    "from llama_index import ServiceContext, VectorStoreIndex, SimpleDirectoryReader, set_global_service_context\n",
    "import transformers\n",
    "from llama_index.llms import HuggingFaceLLM\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set dummy OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # @title Set dummy OpenAI API key\n",
    " # @markdown Without it, we will run into an authentication error ('no API key set')\n",
    "os.environ['OPENAI_API_KEY']='sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'gte-large' already exists and is not an empty directory.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ServiceContext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39m#remove git repo to avoid issues\u001b[39;00m\n\u001b[1;32m      6\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mrm -rf ./gte-large/.git\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m service_context \u001b[39m=\u001b[39m ServiceContext\u001b[39m.\u001b[39mfrom_defaults(\n\u001b[1;32m     10\u001b[0m   embed_model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlocal:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m model\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m set_global_service_context(service_context)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ServiceContext' is not defined"
     ]
    }
   ],
   "source": [
    "# @title Set embedding model\n",
    "# @markdown Highest rated in [MTEB benchmark](https://huggingface.co/spaces/mteb/leaderboard) for document retrieval is thenlper/gte-large\n",
    "model = 'thenlper/gte-large' # @param {type:'string'}\n",
    "!git clone https://huggingface.co/thenlper/gte-large\n",
    "#remove git repo to avoid issues\n",
    "!rm -rf ./gte-large/.git\n",
    "\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "  embed_model=\"local:\" + model\n",
    ")\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Initialize empty index with the given context to use our local embedding model\n",
    "index = VectorStoreIndex([], service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define recursive function to add documents to the index by travelling folders and subfolders\n",
    "\n",
    "\n",
    "#| export\n",
    "def recursive_folder_search(folder):\n",
    "    # get a list of all subdirectories in the given folder\n",
    "    subdirectories = [f.path for f in os.scandir(folder) if f.is_dir()]\n",
    "    # if there are no subdirectories, run the code\n",
    "    if len(subdirectories) == 0:\n",
    "        f=0\n",
    "        for files in os.listdir(folder):\n",
    "          document = SimpleDirectoryReader(folder).load_data()[f]\n",
    "          f+=1\n",
    "          index.insert(document)\n",
    "    else:\n",
    "        # if there are subdirectories, recursively call this function on each subdirectory\n",
    "        for subdirectory in subdirectories:\n",
    "            recursive_folder_search(subdirectory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Train vectorstore index\n",
    "recursive_folder_search(\"../dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Save index to disk\n",
    "index.storage_context.persist(persist_dir=\"indexes/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Retrieve chunks\n",
    "# @markdown Once finished, we can use the already loaded index to test and retrieve chunks\n",
    "retriever = index.as_retriever()\n",
    "searchTerm = 'search term' # @param {type:'string'}\n",
    "nodes = retriever.retrieve(searchTerm)\n",
    "\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
