{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/franfram/llmtools/blob/main/nbs/02_Train_vectorstore_index_with_Llamaindex.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franfram/llmtools/llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# @title Install and import dependencies\n",
    "# !pip install llama-index transformers accelerate sentence_transformers\n",
    "from llama_index import ServiceContext, VectorStoreIndex, SimpleDirectoryReader, set_global_service_context\n",
    "import transformers\n",
    "from llama_index.llms import HuggingFaceLLM\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set dummy OpenAI API key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/franfram/llmtools/blob/main/nbs/02_Train_vectorstore_index_with_Llamaindex.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # @title Set dummy OpenAI API key\n",
    " # @markdown Without it, we will run into an authentication error ('no API key set')\n",
    "os.environ['OPENAI_API_KEY']='sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repo already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/franfram/.cache/torch/sentence_transformers/thenlper_gte-large. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "# @title Set embedding model\n",
    "# @markdown Highest rated in [MTEB benchmark](https://huggingface.co/spaces/mteb/leaderboard) for document retrieval is thenlper/gte-large\n",
    "model = 'thenlper/gte-large' # @param {type:'string'}\n",
    "if not os.path.exists('gte-large'): \n",
    "  !git clone https://huggingface.co/thenlper/gte-large\n",
    "  print(\"Cloning repo\")\n",
    "else:\n",
    "  print(\"repo already exists\")\n",
    "\n",
    "#remove git repo to avoid issues\n",
    "!rm -rf ./gte-large/.git\n",
    "\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "  embed_model=\"local:\" + model\n",
    ")\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Initialize empty index with the given context to use our local embedding model\n",
    "index = VectorStoreIndex([], service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define recursive function to add documents to the index by travelling folders and subfolders\n",
    "\n",
    "\n",
    "#| export\n",
    "def recursive_folder_search(folder):\n",
    "    # get a list of all subdirectories in the given folder\n",
    "    subdirectories = [f.path for f in os.scandir(folder) if f.is_dir()]\n",
    "    # if there are no subdirectories, run the code\n",
    "    if len(subdirectories) == 0:\n",
    "        f=0\n",
    "        for files in os.listdir(folder):\n",
    "          document = SimpleDirectoryReader(folder).load_data()[f]\n",
    "          f+=1\n",
    "          index.insert(document)\n",
    "    else:\n",
    "        # if there are subdirectories, recursively call this function on each subdirectory\n",
    "        for subdirectory in subdirectories:\n",
    "            recursive_folder_search(subdirectory)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Train vectorstore index\n",
    "recursive_folder_search(\"../dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Save index to disk\n",
    "index.storage_context.persist(persist_dir=\"indexes/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Retrieve chunks\n",
    "# @markdown Once finished, we can use the already loaded index to test and retrieve chunks\n",
    "retriever = index.as_retriever()\n",
    "searchTerm = 'search term' # @param {type:'string'}\n",
    "nodes = retriever.retrieve(searchTerm)\n",
    "\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/franfram/llmtools/blob/main/nbs/02_Train_vectorstore_index_with_Llamaindex.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
